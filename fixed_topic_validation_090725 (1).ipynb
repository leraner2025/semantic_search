{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kvmlI0Q2J_D3",
    "outputId": "4cd4015f-ccfd-4eaf-cbe8-a82a6465b6a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
      "Collecting bertopic\n",
      "  Downloading bertopic-0.17.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: hdbscan in /usr/local/lib/python3.11/dist-packages (0.8.40)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Collecting scann\n",
      "  Downloading scann-1.4.0-cp311-cp311-manylinux_2_27_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.5.9.post2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.2)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n",
      "Requirement already satisfied: llvmlite>0.36.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.43.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan) (1.5.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from scann) (5.29.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (8.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.6.15)\n",
      "Downloading bertopic-0.17.3-py3-none-any.whl (153 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scann-1.4.0-cp311-cp311-manylinux_2_27_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scann, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bertopic\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed bertopic-0.17.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 scann-1.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
      "Requirement already satisfied: bertopic in /usr/local/lib/python3.11/dist-packages (0.17.3)\n",
      "Requirement already satisfied: hdbscan in /usr/local/lib/python3.11/dist-packages (0.8.40)\n",
      "Requirement already satisfied: umap-learn in /usr/local/lib/python3.11/dist-packages (0.5.9.post2)\n",
      "Requirement already satisfied: scann in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.0.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from bertopic) (2.2.2)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (5.24.1)\n",
      "Requirement already satisfied: llvmlite>0.36.0 in /usr/local/lib/python3.11/dist-packages (from bertopic) (0.43.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from hdbscan) (1.5.1)\n",
      "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.60.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn) (0.5.13)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from scann) (5.29.5)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->bertopic) (2025.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.7.0->bertopic) (8.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.6.15)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.3.0)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
      "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.15.3\n",
      "    Uninstalling scipy-1.15.3:\n",
      "      Successfully uninstalled scipy-1.15.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scann 1.4.0 requires numpy~=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "89017c00cc8b43329195431d0efb08cd",
       "pip_warning": {
        "packages": [
         "numpy",
         "scipy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install numpy sentence-transformers bertopic hdbscan nltk scann\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "!pip install sentence-transformers bertopic hdbscan umap-learn scann nltk datasets\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "20827be384d24edd8b670dc658261ea4",
      "424619bb47cb4269ab6885aa093b7ab7",
      "d57e5a505956425aaf931c22330dba93",
      "6f7961c0bc6a46eea570f180dfe5c63f",
      "76e7d4b3d00e47a897b7927b14ec377e",
      "32323542eab7480eac83a710cc834533",
      "b739c88f30264726bb5cd1430ca56e76",
      "b665aaf33c224984891349520ea5a418",
      "28ba7af81ffb4f7ba336a76b3058ca57",
      "367a099d2aa54d8696883a003442d9f7",
      "20999225f29d4dffbf4b84b877d716bd",
      "ffac52c8dc3d480eb99dcd5564d7303a",
      "93dd9b548557436a98bf5ffef3bdb963",
      "75f92273178f470d99e8207f2f6635ed",
      "4e32af0b02ad47d4aa66da30fb21b238",
      "995ae2a207f7443492d068bc5c989e11",
      "a2217da6495a448fbe960b2c78c56ef1",
      "c796bcd40ce244b3a2af86fe5a974504",
      "8f544acab67b43fba1abee2503d5060f",
      "c78086aa431d4801aee5c28957ba0f33",
      "3667ca7d149e4b55ac22de3e5203fa1f",
      "8fd55101cfdc4705a9ea297f44c8b7ae",
      "9cdb3a9f708947bfb8df4e74ea48f425",
      "80c93983a6814ca886a7e5ca1f1ecc2e",
      "5e85cfa04e184d2ea7b6d0ccb05f86f8",
      "fd6e18a4e9f44bda8a7fbde1dfb3b7fd",
      "a2b277aa6ece4e31bede38655472161a",
      "56fd3aa1898c489d9a07b8d462389627",
      "84bae7c77c63488b84b05da3e5b98de4",
      "d0d8b79d910d418bb37ccc3750858998",
      "a1279e6a26cc424e88a5b73961d9e1b0",
      "0c320b74dca441edaa704051d4e68e89",
      "685eed7e3b054844a68d77e341a555a5",
      "2c4b9698c01c440dbc36bf2394b7b338",
      "c81094e730384c8dbec50f51b84bc1ac",
      "f6d2ed4f7cf24f939e38dcf0e11b731e",
      "b95ad65975d2453687e4b3c17648a708",
      "5c3ee4bed3d3442c9ec3858fa6c24896",
      "5e9e416be18a4091a1a9a92badb2c276",
      "cad2c0fd97a84cafa9bf632cc746e0b9",
      "8a3c5020aef24ecb9ee1458c51028228",
      "f22601a0f8994b8699f950c33c048742",
      "f4a25a23b29e44029f8742be368451b2",
      "fada7d4f942e46c28ee7ca914d41cc1e",
      "4f57652036c64d73a6b7de5f4b71e0ce",
      "d19d2d21be0b4a01afe6b2ecb5a202c7",
      "5ec2051c3b564a91a5ddd3b4f26ace9d",
      "8b3e2ee1b88d471a9101f6a57c02478a",
      "3edb390a3530474885d4d1d3692166ca",
      "cb1f493d9a944b86a5604eed180c9db9",
      "deea0a1a01dd42e69a0ed4481cc8e2e4",
      "d9f99ef3c0374c12b29244380817af21",
      "d2d24e4951f64646a80e025105515a8f",
      "432ac1d9bab5467a835588c1b94bf023",
      "e54cf913178e49569d75d795b1a419c4",
      "f83236bb306a400ea1f5fd09937722e8",
      "e186b9bc5ab948989b23596a1bbd0674",
      "a13c07c3792a4c3098f95eb4d97f5d17",
      "5d637ce13be348e48f130aa6675f46ba",
      "bc68c22e8aa14a7daf63ede87ade8270",
      "faeb69d50f1a4e5daa7dfee960be26fd",
      "e60c1a242a47428a933cd7085c72d546",
      "e73cbd741c854ba9b7e5d7818bfa28f4",
      "76b130af7f694436943dc9af6096486a",
      "7d20389e00594391a2ae77bb42035eca",
      "de94b3ad5b2c47d883aed8bb479e7575",
      "583ad72cf0fe4e579fc446f34d971a12",
      "cd289990fca647fcade1e11ae0b85377",
      "33aae5dc6524470e93e98eff83670b88",
      "f2883ef863e84f22ad46e1d376817fd0",
      "c64d6a468d744dfa863cbe9433c104e0",
      "373046103a6c4795a48faf1620a5c1b1",
      "c1610f5ee34546d49b84dd0125722a45",
      "50bc29cbcfb1403ababb9c8507b0f2a6",
      "0646585a29b64478841bd99ff2eb3b95",
      "e5634101568c4d2a9cb9195870cd432f",
      "7bb11523ade74232b2bfce5176939951",
      "031064c8324049fd8e3bffda4246a34f",
      "a34b779bbc44473dab059a021e545c51",
      "1999f87af97c43f7b4d2d8fffedc52e1",
      "2c3c147ece9e4063bfdca7d102ccef17",
      "134a7e2cd7dc4bc289a24a38cdc608fc",
      "d8ae57e2338a4f7a86902b309f7f991d",
      "abd530c9bad14954b3ae3af71524ad09",
      "8fd06d1c0799444cb0a5c45c504905da",
      "051c8def9a3940c289099b058c6adb39",
      "97f15e3b443743338a54d16e7a76a540",
      "59cf38b799eb48a8ab574daefa302b22",
      "241fe775c227438e8b75e506ec937665",
      "82d64072878b4005b0c7868d30ab77d0",
      "0620f11e51df493f8098e2cdc405acfb",
      "3d8e2055a79742fe8b54d2e4ce65254c",
      "fd74d4b1004b48ec861dab792e2fdd15",
      "3f66e3fca8d64789b1e2aa7d80bcfa28",
      "02cdcd90c42f4d8989ccda3bf21d5e23",
      "71e2bca9978e4f8f83e184ab55489942",
      "433c05bc37b947e7b86c3698c99c4fa2",
      "8603343258c248e780b01efe9f7275b1",
      "1cdb9e81062f4668bec45e75fcb7a717",
      "2a660a7b3a3246418adc0904f0af5342",
      "1ab91493986744d5ac8369388d327240",
      "f377969a099942d5a05a3759740950b0",
      "6a202b20752446a2984cf996ba64bb4b",
      "38e2672e1cb44be6910e9f10ffc26c98",
      "16a5bb1ffb9a401b951c1b8791aced78",
      "d68436b6777f4d93a0ecffe147749189",
      "75d5167c957f4584867454b29da891c5",
      "2027c9560a6b41fea718c9e39b42dd4b",
      "cce5a9dd027d45b0b3407be052d589f7",
      "ef838a5be5054092a4869556c46a412d",
      "4c0389485fea4ebcb72160c69977bf0a",
      "7eb096819ed4411ca17e0797493d60e3",
      "aad4e35cda084ce199a60dcb2c9e9dfb",
      "5999ae3aee074b98807f33df0fba3aa5",
      "297b595395ac4926a79c1db136f64e42",
      "8900ca4cc4bc43dfad0377b366ac1b8c",
      "105d8ef3721b4b809100feac4f6b5b47",
      "52ff7fcf060c46e8ac83ead82d4b5cc3",
      "6c1e337eb8164873853f3bd8ec850469",
      "7e51133693f6482faf523ac1442c3c78",
      "e2f36056a93940a7bdd1ddbf6cc6d62c"
     ]
    },
    "id": "ZI-E0l4XIUdg",
    "outputId": "135cb445-582b-4653-938e-e2326dbd7526"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Allergy Topic Searcher...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20827be384d24edd8b670dc658261ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffac52c8dc3d480eb99dcd5564d7303a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdb3a9f708947bfb8df4e74ea48f425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4b9698c01c440dbc36bf2394b7b338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f57652036c64d73a6b7de5f4b71e0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f83236bb306a400ea1f5fd09937722e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583ad72cf0fe4e579fc446f34d971a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031064c8324049fd8e3bffda4246a34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241fe775c227438e8b75e506ec937665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a660a7b3a3246418adc0904f0af5342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0389485fea4ebcb72160c69977bf0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Topics and Associated Entities ===\n",
      "Topic ID: 3, Entities: swelling, peanut allergy, hives\n",
      "Topic ID: 2, Entities: epinephrine, treatment, anaphylaxis\n",
      "Topic ID: 0, Entities: pollen, allergic rhinitis, dust, hay fever, allergy symptoms, pet dander, cold weather\n",
      "Topic ID: 1, Entities: food allergies, eggs, urticaria, milk, eczema\n",
      "✅ Model ready for querying.\n",
      "\n",
      "=== Topic Quality Metrics ===\n",
      "🧪 Coherence Score (c_v): 0.6967 (Higher is better, usually >0.4 is decent)\n",
      "🌈 Topic Diversity: 0.8750 (Closer to 1 means more unique topics)\n",
      "📐 Silhouette Score (cosine): 0.7373 (Closer to 1 means better cluster separation)\n",
      "\n",
      "=== Allergy Topic Search ===\n",
      "\n",
      "Enter a query (or type 'exit' to quit): allergy\n",
      "\n",
      "🔎 Top results for: 'allergy'\n",
      "🧠 Topic ID: 0\n",
      "🔗 Related Entities: pollen, allergic rhinitis, dust, hay fever, allergy symptoms, pet dander, cold weather\n",
      "✓ cold weather does not cause allergy symptoms in this patient.\n",
      "✓ allergic rhinitis, or hay fever, results from exposure to pollen, dust, or pet dander.\n",
      "\n",
      "Enter a query (or type 'exit' to quit): symptoms of allergy\n",
      "\n",
      "🔎 Top results for: 'symptoms of allergy'\n",
      "🧠 Topic ID: 0\n",
      "🔗 Related Entities: pollen, allergic rhinitis, dust, hay fever, allergy symptoms, pet dander, cold weather\n",
      "✓ cold weather does not cause allergy symptoms in this patient.\n",
      "✓ allergic rhinitis, or hay fever, results from exposure to pollen, dust, or pet dander.\n",
      "\n",
      "Enter a query (or type 'exit' to quit): how to treat the allergy\n",
      "\n",
      "🔎 Top results for: 'how to treat the allergy'\n",
      "🧠 Topic ID: 3\n",
      "🔗 Related Entities: swelling, peanut allergy, hives\n",
      "✓ patient has peanut allergy causing hives and swelling.\n",
      "\n",
      "Enter a query (or type 'exit' to quit): causes\n",
      "\n",
      "🔎 Top results for: 'causes'\n",
      "🧠 Topic ID: 1\n",
      "🔗 Related Entities: food allergies, eggs, urticaria, milk, eczema\n",
      "✓ food allergies to milk and eggs can cause skin reactions like urticaria and eczema.\n",
      "\n",
      "Enter a query (or type 'exit' to quit): exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS ===\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "import logging\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "import scann\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# === ENVIRONMENT SETUP ===\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# === CLASS FOR TOPIC SEARCHER ===\n",
    "class AllergyTopicSearcher:\n",
    "    def __init__(self, chunks, entities_per_chunk, umap_params, hdbscan_params, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.chunks = chunks\n",
    "        self.entities_per_chunk = entities_per_chunk\n",
    "        self.embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "        self.umap_params = umap_params\n",
    "        self.hdbscan_params = hdbscan_params\n",
    "\n",
    "        self.topic_model = None\n",
    "        self.topic_metadata = []\n",
    "        self.topic_embeddings = None\n",
    "        self.searcher = None\n",
    "\n",
    "        self._prepare()\n",
    "\n",
    "    def _prepare(self):\n",
    "        entity_context_pairs = []\n",
    "\n",
    "        for idx, ents in enumerate(self.entities_per_chunk):\n",
    "            chunk = self.chunks[idx].lower()\n",
    "            sentences = sent_tokenize(chunk)\n",
    "            for ent in ents:\n",
    "                ent_lower = ent.lower()\n",
    "                for sent in sentences:\n",
    "                    if ent_lower in sent:\n",
    "                        entity_context_pairs.append((ent_lower, sent.strip()))\n",
    "                        break\n",
    "\n",
    "        if not entity_context_pairs:\n",
    "            raise ValueError(\"No entity-context pairs extracted!\")\n",
    "\n",
    "        # Embed entity-contexts\n",
    "        contextual_texts = [f\"{ent}: {context}\" for ent, context in entity_context_pairs]\n",
    "        contextual_embeddings = self.embedding_model.encode(contextual_texts, normalize_embeddings=True)\n",
    "\n",
    "        # Topic Modeling\n",
    "        umap_model = UMAP(**self.umap_params)\n",
    "        hdbscan_model = HDBSCAN(**self.hdbscan_params, prediction_data=True)\n",
    "\n",
    "        self.topic_model = BERTopic(\n",
    "            embedding_model=self.embedding_model,\n",
    "            umap_model=umap_model,\n",
    "            hdbscan_model=hdbscan_model,\n",
    "            representation_model=KeyBERTInspired(),\n",
    "            calculate_probabilities=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        topics, _ = self.topic_model.fit_transform(contextual_texts, embeddings=contextual_embeddings)\n",
    "\n",
    "        # Metadata aggregation\n",
    "        topic_to_contexts = defaultdict(list)\n",
    "        topic_to_entities = defaultdict(set)\n",
    "        topic_to_embeddings = defaultdict(list)\n",
    "\n",
    "        for i, topic in enumerate(topics):\n",
    "            ent, context = entity_context_pairs[i]\n",
    "            topic_to_contexts[topic].append(context)\n",
    "            topic_to_entities[topic].add(ent)\n",
    "            topic_to_embeddings[topic].append(contextual_embeddings[i])\n",
    "\n",
    "        topic_embeddings = []\n",
    "        topic_metadata = []\n",
    "\n",
    "        for topic_id in topic_to_contexts:\n",
    "            embeddings = topic_to_embeddings[topic_id]\n",
    "            mean_emb = np.mean(embeddings, axis=0)\n",
    "            mean_emb /= np.linalg.norm(mean_emb) + 1e-10\n",
    "            topic_embeddings.append(mean_emb)\n",
    "            topic_metadata.append({\n",
    "                \"topic_id\": topic_id,\n",
    "                \"entities\": list(topic_to_entities[topic_id]),\n",
    "                \"sentences\": topic_to_contexts[topic_id],\n",
    "                \"sentence_embeddings\": np.array(embeddings)\n",
    "            })\n",
    "\n",
    "        self.topic_embeddings = np.array(topic_embeddings)\n",
    "        self.topic_metadata = topic_metadata\n",
    "\n",
    "        # === Print topics and their entities ===\n",
    "        print(\"\\n=== Topics and Associated Entities ===\")\n",
    "        for meta in self.topic_metadata:\n",
    "            print(f\"Topic ID: {meta['topic_id']}, Entities: {', '.join(meta['entities'])}\")\n",
    "\n",
    "        if len(self.topic_embeddings) < 1:\n",
    "            raise RuntimeError(\"No topic embeddings to index.\")\n",
    "\n",
    "        num_clusters = min(len(self.topic_embeddings), 3)\n",
    "        self.searcher = (\n",
    "            scann.scann_ops_pybind.builder(self.topic_embeddings, 3, \"dot_product\")\n",
    "            .tree(num_leaves=num_clusters, num_leaves_to_search=2, training_sample_size=len(self.topic_embeddings))\n",
    "            .score_brute_force()\n",
    "            .reorder(3)\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "    def search(self, query, top_k_topics=1, top_k_sents=1):\n",
    "        query_emb = self.embedding_model.encode([query], normalize_embeddings=True)[0]\n",
    "        neighbors, scores = self.searcher.search(query_emb, final_num_neighbors=top_k_topics)\n",
    "\n",
    "        results = []\n",
    "        for idx in neighbors:\n",
    "            meta = self.topic_metadata[idx]\n",
    "            seen = set()\n",
    "            unique_sentences = []\n",
    "            unique_embeddings = []\n",
    "\n",
    "            for sent, emb in zip(meta[\"sentences\"], meta[\"sentence_embeddings\"]):\n",
    "                if sent not in seen:\n",
    "                    seen.add(sent)\n",
    "                    unique_sentences.append(sent)\n",
    "                    unique_embeddings.append(emb)\n",
    "\n",
    "            sent_embs = np.array(unique_embeddings)\n",
    "            sent_embs_norm = sent_embs / np.linalg.norm(sent_embs, axis=1, keepdims=True)\n",
    "            sims = np.dot(sent_embs_norm, query_emb)\n",
    "            top_indices = sims.argsort()[::-1][:top_k_sents]\n",
    "            top_sents = [(unique_sentences[i], sims[i]) for i in top_indices]\n",
    "\n",
    "            results.append({\n",
    "                \"topic_id\": meta[\"topic_id\"],\n",
    "                \"entities\": meta[\"entities\"],\n",
    "                \"sentences\": top_sents,\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "# === COHERENCE SCORE ===\n",
    "def compute_bertopic_coherence(topic_model, topic_metadata, topk=10):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    topic_word_lists = [[word for word, _ in topic] for topic in topics]\n",
    "\n",
    "    texts = []\n",
    "    for meta in topic_metadata:\n",
    "        sentences = meta[\"sentences\"]\n",
    "        for sent in sentences:\n",
    "            tokens = [word for word in sent.lower().split()]\n",
    "            texts.append(tokens)\n",
    "\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_word_lists,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence=\"c_v\"\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    return coherence_score\n",
    "\n",
    "# === TOPIC DIVERSITY ===\n",
    "def compute_topic_diversity(topic_model, topic_metadata, topk=10):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    all_words = []\n",
    "    for topic in topics:\n",
    "        all_words.extend([word for word, _ in topic])\n",
    "    unique_words = set(all_words)\n",
    "    diversity = len(unique_words) / (len(topics) * topk)\n",
    "    return diversity\n",
    "\n",
    "# === SILHOUETTE SCORE (sentence embeddings, avoid errors) ===\n",
    "def compute_silhouette_score(topic_metadata):\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for meta in topic_metadata:\n",
    "        embeddings = meta[\"sentence_embeddings\"]  # (num_sentences, emb_dim)\n",
    "        labels = [meta[\"topic_id\"]] * len(embeddings)\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0:\n",
    "        return None\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    n_samples = all_embeddings.shape[0]\n",
    "    n_labels = len(set(all_labels))\n",
    "\n",
    "    if n_labels < 2 or n_labels > n_samples - 1:\n",
    "        return None  # silhouette score constraints\n",
    "\n",
    "    return silhouette_score(all_embeddings, all_labels, metric=\"cosine\")\n",
    "\n",
    "# === DATASET ===\n",
    "allergy_dataset = {\n",
    "    \"name\": \"Allergy Dataset\",\n",
    "    \"chunks\": [\n",
    "        \"Patient has peanut allergy causing hives and swelling. Anaphylaxis noted once during a reaction.\",\n",
    "        \"Allergic rhinitis, or hay fever, results from exposure to pollen, dust, or pet dander.\",\n",
    "        \"Severe anaphylaxis symptoms require immediate treatment with epinephrine.\",\n",
    "        \"Food allergies to milk and eggs can cause skin reactions like urticaria and eczema.\",\n",
    "        \"Cold weather does not cause allergy symptoms in this patient.\"\n",
    "    ],\n",
    "    \"entities\": [\n",
    "        [\"peanut allergy\", \"hives\", \"swelling\", \"anaphylaxis\"],\n",
    "        [\"allergic rhinitis\", \"hay fever\", \"pollen\", \"dust\", \"pet dander\"],\n",
    "        [\"anaphylaxis\", \"epinephrine\", \"treatment\"],\n",
    "        [\"food allergies\", \"milk\", \"eggs\", \"urticaria\", \"eczema\"],\n",
    "        [\"cold weather\", \"allergy symptoms\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# === BEST PARAMETERS ===\n",
    "best_umap = {\"n_neighbors\": 5, \"n_components\": 5, \"min_dist\": 0.1, \"metric\": \"cosine\"}\n",
    "best_hdbscan = {\"min_cluster_size\": 2, \"min_samples\": 1, \"metric\": \"euclidean\"}\n",
    "\n",
    "# === INITIALIZE SEARCHER ===\n",
    "print(\"Preparing Allergy Topic Searcher...\")\n",
    "searcher = AllergyTopicSearcher(\n",
    "    chunks=allergy_dataset[\"chunks\"],\n",
    "    entities_per_chunk=allergy_dataset[\"entities\"],\n",
    "    umap_params=best_umap,\n",
    "    hdbscan_params=best_hdbscan,\n",
    ")\n",
    "print(\"✅ Model ready for querying.\")\n",
    "\n",
    "# === EVALUATION METRICS ===\n",
    "coherence = compute_bertopic_coherence(searcher.topic_model, searcher.topic_metadata, topk=10)\n",
    "diversity = compute_topic_diversity(searcher.topic_model, searcher.topic_metadata, topk=10)\n",
    "sil_score = compute_silhouette_score(searcher.topic_metadata)\n",
    "\n",
    "print(\"\\n=== Topic Quality Metrics ===\")\n",
    "print(f\"🧪 Coherence Score (c_v): {coherence:.4f} (Higher is better, usually >0.4 is decent)\")\n",
    "print(f\"🌈 Topic Diversity: {diversity:.4f} (Closer to 1 means more unique topics)\")\n",
    "if sil_score is not None:\n",
    "    print(f\"📐 Silhouette Score (cosine): {sil_score:.4f} (Closer to 1 means better cluster separation)\")\n",
    "else:\n",
    "    print(\"📐 Silhouette Score: Not applicable (need at least 2 topics and enough samples).\")\n",
    "\n",
    "# === QUERY LOOP ===\n",
    "print(\"\\n=== Allergy Topic Search ===\")\n",
    "while True:\n",
    "    query = input(\"\\nEnter a query (or type 'exit' to quit): \").strip()\n",
    "    if query.lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    results = searcher.search(query, top_k_topics=1, top_k_sents=3)\n",
    "    print(f\"\\n🔎 Top results for: '{query}'\")\n",
    "    for res in results:\n",
    "        print(f\"🧠 Topic ID: {res['topic_id']}\")\n",
    "        print(f\"🔗 Related Entities: {', '.join(res['entities'])}\")\n",
    "        for sent, _ in res[\"sentences\"]:\n",
    "            print(f\"✓ {sent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxtIeeAn7r6a"
   },
   "outputs": [],
   "source": [
    "#code after improved topic modelling metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3be88f1299024bd58bd93e465c4b9f7c",
      "8a50759cc6254569820714e0cb6d52ec",
      "25c9856f9f0847698511afbbdcf0ba20",
      "6dfc4e57cf0148d49896b5b922eea753",
      "b6de64b0717148c1996870eb2e6cfe1b",
      "4d10440e602f4867a7fcc71e404df51d",
      "ab96c972337e4536900287c18373e414",
      "17ffcf8d3db04f97ab26836caa07aeca",
      "9b55483d8c19473c8786695c3a5cd827",
      "9ad1a1bcbdeb4aaf9f24ae61c66e0366",
      "b9fba652f1964859a3f1480392cd8985",
      "827009acb20446bf8d2b7b469cd9dc51",
      "50e2b0f172ee4b1a84c26b355de95ee7",
      "fe11da15726a40b49d5dc2202fa1a347",
      "a44853c43c5b4bae861758eb2890d768",
      "f957dd0d1d1647e685bd89933533355b",
      "30f94b4cf9234271bec3dfc56c7856e5",
      "31c22cdd9bc347328726da07e7c1d172",
      "05c9d189b87e4ade81465dfc477ce3c3",
      "5413d2b3fd0540ac8ea5722863ee5ddf",
      "4c160cc14b8d4b5c9ddcc9d27d75db61",
      "a99d0af9351548c6925caf202e34613b",
      "49e7f33d1ee8417ebe0cd2ea8e174e34",
      "72dce6889bfb40599278b7848def16b3",
      "b87a43a0db444adda47d75c19b25b114",
      "73c683ef477e40ecb98836583a575da5",
      "115c9cf9bf654f3f807e27c4759aa2f3",
      "3f3eec3b7ebe43aaa1b9d139c517eb2f",
      "848bd26b5dd14c3895b962250c3aa726",
      "ad62085142bb4ca9a60c2a4ddd7e6c15",
      "b15c53c8eeb84b6e81c0f5e59c238827",
      "ce72c5206b9546938f3e3810fed79344",
      "bb7ba665a53a41eb80307645faf73fd9",
      "91054171694248cf9d26789d74fa27a8",
      "412f502d842f4164a270afb56bee5a1a",
      "4d4c093bc50b4d699305c8bb56061aa8",
      "611bfff133924654a4dea4b4f0fa8e5f",
      "722c4567aeef43b3975e2a6b74b0ac87",
      "a904b4bcccac4544856f2f681f07f878",
      "93149029aa6648a8a5f7ef6bf41518a5",
      "2f9fd56764ae49658c9e0760885f241f",
      "caee89e0fba8470dab40c75ed3deef82",
      "a78889d729fa48e3b5565da5b856947e",
      "78ce74fb987443c4b509b74bdc0b50c1",
      "cc3c0944d37c4a02bc04b623c38cf5e8",
      "b1d9256018b24f8ca14a10cc1ec2567b",
      "98ca6cf35ceb4a968aaee27633b5db08",
      "833ae2955acd48408baf67f4fdaebe8a",
      "8d4b1e56a7c0472bac67f8ab7680043e",
      "7ba8f51807cb47e4879566ebda3fbede",
      "6e7fe57f6ae941b3ae7b2fd00e8fdcc0",
      "f03657291c05407db97283cb16a3ed47",
      "cd7e0484431741969702f0d11fd66678",
      "9eb0329e0d1e407db00683b341b46a2d",
      "d55029a5a11344fe83d267d8e3607e94",
      "8e9576a7e79642e98aca4bd9a1a106cd",
      "b39e27a2ee39476a919cc68f55e47b81",
      "877c71d1578244489fbc223c5ea510bc",
      "c683abaebec34153a9492dfa18f93da5",
      "19ee111df5f64cd8bd35d6452e26a07f",
      "26217e773f2c4fbf8b2c843f9e8d7a81",
      "1adc1c2a4ac04b7c90ddeaa8370f7443",
      "959feec9f8e04940ae417041926fca17",
      "49c238d72e734a0590c4808ef2e2b700",
      "53dbcf3d25524db98b0c3c68b2ce5567",
      "edeb5f64a3f24914b182c6b80e4dcfd8",
      "609d040786f34289a05478bf7ba712f5",
      "07466973630d427884d663e38d3569b9",
      "f75ce54d40224bb394e11a54efa6b297",
      "d4952f10dd0e48bdafc87765bc6cf8bf",
      "601e5a7d0a074035a467ef70628ae501",
      "2ab85a452f214591a80d4c8b3735c65f",
      "b5d55125935d46298cb2e195b3ae26de",
      "60071a1d81b647e58397f3c44208f7f3",
      "5ddc3b963e4d4237979341e1d757c6c1",
      "58806466f9844dc69ce2b8cce8bddbcd",
      "5f4849fa7fd74cfa8280540e72fa37fa",
      "9465836cd23c4aa4bce1c749619308dd",
      "c123c013717a4a7ab5276cd8b9fce87d",
      "572efe857c9f4dc48ddbdb9d6913e029",
      "c895ce8535b2489595d7789aaea3622f",
      "8bf184a5518941b28b7ac3392d06ec86",
      "7b91424783114c6896c94e2ad4831196",
      "762c5967dd3c4ce69e01757be44bbc5d",
      "faa2b0bc183a4dfeb7de6f1265b03f9f",
      "aaf3a7bee43c40c5867424e838b85eb0",
      "66f79581844d40a6944dac64ea487a22",
      "f91c6a438ad948428259cfe8a7e88ba9",
      "9b8a6163331e42eb98e00863656aaa55",
      "71d13386081a4dc7b47721a219ebd467",
      "017def251ca04d098883a053c5e2ad65",
      "48d8c2fd4482404bae49c1a7e170eb97",
      "ad4e6e2c20ab4eb2b2cd9b64362424b5",
      "1b5a1d9fd6164a9b917b433f82c8a089",
      "f40e362fc8b1442cabbaf8efccc50d75",
      "dfba1ee8f6ea4ba7a30d2b1c047db72d",
      "3bb665403a654cf887b21ee476f81e89",
      "62d360a4defe469d996bf14fc7b7202f",
      "619397b009c44963ab606b2ca089cf05",
      "03051fadb5d441789fc44f62f2cff76a",
      "7d23d99b761642c58c8a981eba138d62",
      "ef953cbdf4204006838bef18aeb40fcf",
      "235ab6c161e940ca94cc4e51b95dee8b",
      "8f39680eae6b4f01b297981d2c2fe523",
      "8f4b5445112b41db95acbf52912c31f6",
      "b0dbbe7cd09146c0a178709e7ea12b56",
      "dc7eecba630b4af6befacd78ea9de7f2",
      "a1d422294a99428382cd8fd75c0b381e",
      "46ef3666f42340f98a92c02993e230ea",
      "565a9cbc351744e984a2e4dc3269fcf5",
      "b699837321344f3082259efd5573ea9f",
      "5eb5a3a81c7d43218e44e802ff2f9bac",
      "7fb2b73ac6444cad9e1f56f5830485e3",
      "a15542b9f9124eeea3bdc358acd940e6",
      "8f27036c2b9c43e99c536b8ed7eea7eb",
      "48d73ebaa19046399101faa2705fc317",
      "35380f9ad22546039c2fdbcb5bbbfde1",
      "070d1f41fbc54b8eb50f63500a5873fd",
      "ed2c819511a049588c31ecca0c55a390",
      "6425c59cb755463c8de392c34d8e68db",
      "ef3b9865949d449ba33d7610b2033371"
     ]
    },
    "id": "uyTkRC3EK_Ws",
    "outputId": "5e36b6ed-11c6-4bd4-bf8f-811077c1a0eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Allergy Topic Searcher...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be88f1299024bd58bd93e465c4b9f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827009acb20446bf8d2b7b469cd9dc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e7f33d1ee8417ebe0cd2ea8e174e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91054171694248cf9d26789d74fa27a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3c0944d37c4a02bc04b623c38cf5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9576a7e79642e98aca4bd9a1a106cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609d040786f34289a05478bf7ba712f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9465836cd23c4aa4bce1c749619308dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8a6163331e42eb98e00863656aaa55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03051fadb5d441789fc44f62f2cff76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b699837321344f3082259efd5573ea9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Topics and Associated Entities ===\n",
      "Topic ID: 0, Entities: peanut allergy, swelling, anaphylaxis, hives, allergy symptoms, cold weather\n",
      "Topic ID: 1, Entities: pollen, allergic rhinitis, dust, hay fever, pet dander\n",
      "Topic ID: 3, Entities: epinephrine, treatment, anaphylaxis\n",
      "Topic ID: 2, Entities: food allergies, eggs, urticaria, milk, eczema\n",
      "✅ Model ready for querying.\n",
      "\n",
      "=== Topic Quality Metrics ===\n",
      "🧪 Coherence Score (c_v): 0.8963\n",
      "🌈 Topic Diversity: 0.8250\n",
      "📐 Silhouette Score: 0.7315\n",
      "\n",
      "=== 📊 Topic Matching Summary ===\n",
      "🔗 Model Topic 0 ↔ Ground Truth T3 — Jaccard: 0.50\n",
      "🔗 Model Topic 1 ↔ Ground Truth T2 — Jaccard: 0.38\n",
      "🔗 Model Topic 3 ↔ Ground Truth T4 — Jaccard: 0.67\n",
      "🔗 Model Topic 2 ↔ Ground Truth T2 — Jaccard: 0.22\n",
      "\n",
      "🧮 Average Jaccard Similarity: 0.4410\n",
      "📈 Ground Truth Coverage: 3/5 (60.0%)\n",
      "\n",
      "=== 🧠 Entity-Level Evaluation ===\n",
      "🎯 Precision: 0.7222\n",
      "🧲 Recall:    0.9286\n",
      "🏅 F1 Score:  0.8125\n",
      "\n",
      "=== Allergy Topic Search ===\n",
      "\n",
      "Enter a query (or type 'exit' to quit): allergy\n",
      "\n",
      "🔎 Top results for: 'allergy'\n",
      "🧠 Topic ID: 0\n",
      "🔗 Related Entities: peanut allergy, swelling, anaphylaxis, hives, allergy symptoms, cold weather\n",
      "✓ patient has peanut allergy causing hives and swelling anaphylaxis noted once during a reaction\n",
      "✓ cold weather does not cause allergy symptoms in this patient\n",
      "\n",
      "Enter a query (or type 'exit' to quit): symptoms of allergy\n",
      "\n",
      "🔎 Top results for: 'symptoms of allergy'\n",
      "🧠 Topic ID: 0\n",
      "🔗 Related Entities: peanut allergy, swelling, anaphylaxis, hives, allergy symptoms, cold weather\n",
      "✓ patient has peanut allergy causing hives and swelling anaphylaxis noted once during a reaction\n",
      "✓ cold weather does not cause allergy symptoms in this patient\n",
      "\n",
      "Enter a query (or type 'exit' to quit): how to treat allergy\n",
      "\n",
      "🔎 Top results for: 'how to treat allergy'\n",
      "🧠 Topic ID: 3\n",
      "🔗 Related Entities: epinephrine, treatment, anaphylaxis\n",
      "✓ severe anaphylaxis symptoms require immediate treatment with epinephrine\n",
      "\n",
      "Enter a query (or type 'exit' to quit): causes of allergy\n",
      "\n",
      "🔎 Top results for: 'causes of allergy'\n",
      "🧠 Topic ID: 2\n",
      "🔗 Related Entities: food allergies, eggs, urticaria, milk, eczema\n",
      "✓ food allergies to milk and eggs can cause skin reactions like urticaria and eczema\n",
      "\n",
      "Enter a query (or type 'exit' to quit): food\n",
      "\n",
      "🔎 Top results for: 'food'\n",
      "🧠 Topic ID: 2\n",
      "🔗 Related Entities: food allergies, eggs, urticaria, milk, eczema\n",
      "✓ food allergies to milk and eggs can cause skin reactions like urticaria and eczema\n",
      "\n",
      "Enter a query (or type 'exit' to quit): exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS & SETUP ===\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "import logging\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "import scann\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# === CLEANING & CONTEXT EXTRACTION ===\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_entity_contexts(chunks, entities_per_chunk, use_multi_sentence=True):\n",
    "    entity_context_pairs = []\n",
    "    for idx, ents in enumerate(entities_per_chunk):\n",
    "        chunk = clean_text(chunks[idx])\n",
    "        sentences = sent_tokenize(chunk)\n",
    "        for ent in ents:\n",
    "            ent_lower = ent.lower()\n",
    "            matched = False\n",
    "            for i, sent in enumerate(sentences):\n",
    "                if ent_lower in sent.lower():\n",
    "                    context = (\n",
    "                        \" \".join(sentences[max(0, i - 1): i + 2])\n",
    "                        if use_multi_sentence else sent.strip()\n",
    "                    )\n",
    "                    entity_context_pairs.append((ent_lower, context.strip()))\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                entity_context_pairs.append((ent_lower, chunk))\n",
    "    return entity_context_pairs\n",
    "\n",
    "# === TOPIC SEARCHER CLASS ===\n",
    "class AllergyTopicSearcher:\n",
    "    def __init__(self, chunks, entities_per_chunk, umap_params, hdbscan_params, model_name=\"all-mpnet-base-v2\"):\n",
    "        self.chunks = chunks\n",
    "        self.entities_per_chunk = entities_per_chunk\n",
    "        self.embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "        self.umap_params = umap_params\n",
    "        self.hdbscan_params = hdbscan_params\n",
    "\n",
    "        self.topic_model = None\n",
    "        self.topic_metadata = []\n",
    "        self.topic_embeddings = None\n",
    "        self.searcher = None\n",
    "\n",
    "        self._prepare()\n",
    "\n",
    "    def _prepare(self):\n",
    "        entity_context_pairs = extract_entity_contexts(\n",
    "            self.chunks,\n",
    "            self.entities_per_chunk,\n",
    "            use_multi_sentence=True\n",
    "        )\n",
    "\n",
    "        if not entity_context_pairs:\n",
    "            raise ValueError(\"No entity-context pairs extracted!\")\n",
    "\n",
    "        contextual_texts = [f\"{ent}: {context}\" for ent, context in entity_context_pairs]\n",
    "        contextual_embeddings = self.embedding_model.encode(contextual_texts, normalize_embeddings=True)\n",
    "\n",
    "        umap_model = UMAP(**self.umap_params)\n",
    "        hdbscan_model = HDBSCAN(**self.hdbscan_params, prediction_data=True)\n",
    "\n",
    "        self.topic_model = BERTopic(\n",
    "            embedding_model=self.embedding_model,\n",
    "            umap_model=umap_model,\n",
    "            hdbscan_model=hdbscan_model,\n",
    "            representation_model=KeyBERTInspired(),\n",
    "            calculate_probabilities=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        topics, _ = self.topic_model.fit_transform(contextual_texts, embeddings=contextual_embeddings)\n",
    "\n",
    "        topic_to_contexts = defaultdict(list)\n",
    "        topic_to_entities = defaultdict(set)\n",
    "        topic_to_embeddings = defaultdict(list)\n",
    "\n",
    "        for i, topic in enumerate(topics):\n",
    "            ent, context = entity_context_pairs[i]\n",
    "            topic_to_contexts[topic].append(context)\n",
    "            topic_to_entities[topic].add(ent)\n",
    "            topic_to_embeddings[topic].append(contextual_embeddings[i])\n",
    "\n",
    "        topic_embeddings = []\n",
    "        topic_metadata = []\n",
    "\n",
    "        for topic_id in topic_to_contexts:\n",
    "            embeddings = topic_to_embeddings[topic_id]\n",
    "            mean_emb = np.mean(embeddings, axis=0)\n",
    "            mean_emb /= np.linalg.norm(mean_emb) + 1e-10\n",
    "            topic_embeddings.append(mean_emb)\n",
    "            topic_metadata.append({\n",
    "                \"topic_id\": topic_id,\n",
    "                \"entities\": list(topic_to_entities[topic_id]),\n",
    "                \"sentences\": topic_to_contexts[topic_id],\n",
    "                \"sentence_embeddings\": np.array(embeddings)\n",
    "            })\n",
    "\n",
    "        self.topic_embeddings = np.array(topic_embeddings)\n",
    "        self.topic_metadata = topic_metadata\n",
    "\n",
    "        print(\"\\n=== Topics and Associated Entities ===\")\n",
    "        for meta in self.topic_metadata:\n",
    "            print(f\"Topic ID: {meta['topic_id']}, Entities: {', '.join(meta['entities'])}\")\n",
    "\n",
    "        if len(self.topic_embeddings) < 1:\n",
    "            raise RuntimeError(\"No topic embeddings to index.\")\n",
    "\n",
    "        num_clusters = min(len(self.topic_embeddings), 3)\n",
    "        self.searcher = (\n",
    "            scann.scann_ops_pybind.builder(self.topic_embeddings, 3, \"dot_product\")\n",
    "            .tree(num_leaves=num_clusters, num_leaves_to_search=2, training_sample_size=len(self.topic_embeddings))\n",
    "            .score_brute_force()\n",
    "            .reorder(3)\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "    def search(self, query, top_k_topics=1, top_k_sents=1):\n",
    "        query_emb = self.embedding_model.encode([query], normalize_embeddings=True)[0]\n",
    "        neighbors, scores = self.searcher.search(query_emb, final_num_neighbors=top_k_topics)\n",
    "\n",
    "        results = []\n",
    "        for idx in neighbors:\n",
    "            meta = self.topic_metadata[idx]\n",
    "            seen = set()\n",
    "            unique_sentences = []\n",
    "            unique_embeddings = []\n",
    "\n",
    "            for sent, emb in zip(meta[\"sentences\"], meta[\"sentence_embeddings\"]):\n",
    "                if sent not in seen:\n",
    "                    seen.add(sent)\n",
    "                    unique_sentences.append(sent)\n",
    "                    unique_embeddings.append(emb)\n",
    "\n",
    "            sent_embs = np.array(unique_embeddings)\n",
    "            sent_embs_norm = sent_embs / np.linalg.norm(sent_embs, axis=1, keepdims=True)\n",
    "            sims = np.dot(sent_embs_norm, query_emb)\n",
    "            top_indices = sims.argsort()[::-1][:top_k_sents]\n",
    "            top_sents = [(unique_sentences[i], sims[i]) for i in top_indices]\n",
    "\n",
    "            results.append({\n",
    "                \"topic_id\": meta[\"topic_id\"],\n",
    "                \"entities\": meta[\"entities\"],\n",
    "                \"sentences\": top_sents,\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "# === EVALUATION METRICS ===\n",
    "def compute_bertopic_coherence(topic_model, topic_metadata, topk=15):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    topic_word_lists = [[word for word, _ in topic] for topic in topics]\n",
    "\n",
    "    texts = []\n",
    "    for meta in topic_metadata:\n",
    "        for sent in meta[\"sentences\"]:\n",
    "            tokens = clean_text(sent).split()\n",
    "            texts.append(tokens)\n",
    "\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_word_lists,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence=\"c_v\"\n",
    "    )\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "def compute_topic_diversity(topic_model, topic_metadata, topk=10):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    all_words = [word for topic in topics for word, _ in topic]\n",
    "    return len(set(all_words)) / (len(topics) * topk)\n",
    "\n",
    "def compute_silhouette_score_custom(topic_metadata):\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for meta in topic_metadata:\n",
    "        embeddings = meta[\"sentence_embeddings\"]\n",
    "        labels = [meta[\"topic_id\"]] * len(embeddings)\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0:\n",
    "        return None\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    n_samples = all_embeddings.shape[0]\n",
    "    n_labels = len(set(all_labels))\n",
    "\n",
    "    if n_labels < 2 or n_labels > n_samples - 1:\n",
    "        return None\n",
    "\n",
    "    return silhouette_score(all_embeddings, all_labels, metric=\"cosine\")\n",
    "\n",
    "# === DATASET & INITIALIZATION ===\n",
    "allergy_dataset = {\n",
    "    \"chunks\": [\n",
    "        \"Patient has peanut allergy causing hives and swelling. Anaphylaxis noted once during a reaction.\",\n",
    "        \"Allergic rhinitis, or hay fever, results from exposure to pollen, dust, or pet dander.\",\n",
    "        \"Severe anaphylaxis symptoms require immediate treatment with epinephrine.\",\n",
    "        \"Food allergies to milk and eggs can cause skin reactions like urticaria and eczema.\",\n",
    "        \"Cold weather does not cause allergy symptoms in this patient.\"\n",
    "    ],\n",
    "    \"entities\": [\n",
    "        [\"peanut allergy\", \"hives\", \"swelling\", \"anaphylaxis\"],\n",
    "        [\"allergic rhinitis\", \"hay fever\", \"pollen\", \"dust\", \"pet dander\"],\n",
    "        [\"anaphylaxis\", \"epinephrine\", \"treatment\"],\n",
    "        [\"food allergies\", \"milk\", \"eggs\", \"urticaria\", \"eczema\"],\n",
    "        [\"cold weather\", \"allergy symptoms\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "best_umap = {\"n_neighbors\": 5, \"n_components\": 5, \"min_dist\": 0.1, \"metric\": \"cosine\"}\n",
    "best_hdbscan = {\"min_cluster_size\": 2, \"min_samples\": 1, \"metric\": \"euclidean\"}\n",
    "\n",
    "print(\"Preparing Allergy Topic Searcher...\")\n",
    "searcher = AllergyTopicSearcher(\n",
    "    chunks=allergy_dataset[\"chunks\"],\n",
    "    entities_per_chunk=allergy_dataset[\"entities\"],\n",
    "    umap_params=best_umap,\n",
    "    hdbscan_params=best_hdbscan,\n",
    "    model_name=\"all-mpnet-base-v2\"\n",
    ")\n",
    "print(\"✅ Model ready for querying.\")\n",
    "\n",
    "# === METRICS ===\n",
    "coherence = compute_bertopic_coherence(searcher.topic_model, searcher.topic_metadata, topk=15)\n",
    "diversity = compute_topic_diversity(searcher.topic_model, searcher.topic_metadata, topk=10)\n",
    "sil_score = compute_silhouette_score_custom(searcher.topic_metadata)\n",
    "\n",
    "print(\"\\n=== Topic Quality Metrics ===\")\n",
    "print(f\"🧪 Coherence Score (c_v): {coherence:.4f}\")\n",
    "print(f\"🌈 Topic Diversity: {diversity:.4f}\")\n",
    "if sil_score is not None:\n",
    "    print(f\"📐 Silhouette Score: {sil_score:.4f}\")\n",
    "else:\n",
    "    print(\"📐 Silhouette Score: Not applicable.\")\n",
    "\n",
    "# === GROUND TRUTH TOPICS ===\n",
    "ground_truth_topics = [\n",
    "    {\"topic_id\": \"T1\", \"entities\": [\"peanut allergy\", \"allergic rhinitis\", \"hay fever\", \"food allergies\"]},\n",
    "    {\"topic_id\": \"T2\", \"entities\": [\"peanut\", \"pollen\", \"dust\", \"pet dander\", \"milk\", \"eggs\"]},\n",
    "    {\"topic_id\": \"T3\", \"entities\": [\"hives\", \"swelling\", \"anaphylaxis\", \"urticaria\", \"eczema\", \"allergy symptoms\"]},\n",
    "    {\"topic_id\": \"T4\", \"entities\": [\"epinephrine\", \"treatment\"]},\n",
    "    {\"topic_id\": \"T5\", \"entities\": [\"cold weather\"]}\n",
    "]\n",
    "\n",
    "# === EVALUATION CODE ===\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def normalize(entities):\n",
    "    return [e.lower().strip() for e in entities]\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    set1, set2 = set(set1), set(set2)\n",
    "    return len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0.0\n",
    "\n",
    "# Prepare model topics\n",
    "model_topics = [\n",
    "    {\"topic_id\": meta[\"topic_id\"], \"entities\": normalize(meta[\"entities\"])}\n",
    "    for meta in searcher.topic_metadata\n",
    "]\n",
    "\n",
    "# Matching model topics to ground truth\n",
    "matched_gt_ids = set()\n",
    "matches = []\n",
    "all_model_entities = []\n",
    "all_gt_entities = []\n",
    "\n",
    "for mt in model_topics:\n",
    "    best_score = 0\n",
    "    best_gt = None\n",
    "    for gt in ground_truth_topics:\n",
    "        score = jaccard_similarity(mt[\"entities\"], normalize(gt[\"entities\"]))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_gt = gt\n",
    "    if best_gt:\n",
    "        matches.append((mt[\"topic_id\"], best_gt[\"topic_id\"], best_score))\n",
    "        matched_gt_ids.add(best_gt[\"topic_id\"])\n",
    "\n",
    "        # Collect entities for entity-level precision/recall\n",
    "        all_model_entities.extend(mt[\"entities\"])\n",
    "        all_gt_entities.extend(normalize(best_gt[\"entities\"]))\n",
    "\n",
    "# Entity-level metrics\n",
    "model_entity_counter = Counter(all_model_entities)\n",
    "gt_entity_counter = Counter(all_gt_entities)\n",
    "\n",
    "unique_entities = list(set(list(model_entity_counter.keys()) + list(gt_entity_counter.keys())))\n",
    "y_true = [gt_entity_counter[e] > 0 for e in unique_entities]\n",
    "y_pred = [model_entity_counter[e] > 0 for e in unique_entities]\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "# Print evaluation\n",
    "print(\"\\n=== 📊 Topic Matching Summary ===\")\n",
    "for model_id, gt_id, score in matches:\n",
    "    print(f\"🔗 Model Topic {model_id} ↔ Ground Truth {gt_id} — Jaccard: {score:.2f}\")\n",
    "\n",
    "print(f\"\\n🧮 Average Jaccard Similarity: {sum(score for _, _, score in matches) / len(matches):.4f}\")\n",
    "print(f\"📈 Ground Truth Coverage: {len(matched_gt_ids)}/{len(ground_truth_topics)} \"\n",
    "      f\"({(len(matched_gt_ids)/len(ground_truth_topics))*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== 🧠 Entity-Level Evaluation ===\")\n",
    "print(f\"🎯 Precision: {precision:.4f}\")\n",
    "print(f\"🧲 Recall:    {recall:.4f}\")\n",
    "print(f\"🏅 F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# === QUERY LOOP ===\n",
    "print(\"\\n=== Allergy Topic Search ===\")\n",
    "while True:\n",
    "    query = input(\"\\nEnter a query (or type 'exit' to quit): \").strip()\n",
    "    if query.lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    results = searcher.search(query, top_k_topics=1, top_k_sents=3)\n",
    "    print(f\"\\n🔎 Top results for: '{query}'\")\n",
    "    for res in results:\n",
    "        print(f\"🧠 Topic ID: {res['topic_id']}\")\n",
    "        print(f\"🔗 Related Entities: {', '.join(res['entities'])}\")\n",
    "        for sent, _ in res[\"sentences\"]:\n",
    "            print(f\"✓ {sent}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSV1j4V370B6"
   },
   "outputs": [],
   "source": [
    "#Experiemnt on dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_N0T8vWigwl",
    "outputId": "9a72821f-4009-4fde-aa6a-470d3aa60e77"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Allergy Topic Searcher...\n",
      "\n",
      "=== Topics and Associated Entities ===\n",
      "Topic ID: 1, Entities: skin condition, itchy, inflamed skin, atopic dermatitis\n",
      "Topic ID: 3, Entities: infections, scaly patches, dry\n",
      "Topic ID: 2, Entities: treatment, moisturizers, corticosteroids, irritants\n",
      "Topic ID: 4, Entities: severe cases, systemic immunosuppressants\n",
      "Topic ID: 0, Entities: pollen, triggers, allergens, dust mites, pet dander\n",
      "✅ Model ready for querying.\n",
      "\n",
      "=== Topic Quality Metrics ===\n",
      "🧪 Coherence Score (c_v): 0.9420\n",
      "🌈 Topic Diversity: 0.7800\n",
      "📐 Silhouette Score: 0.8139\n",
      "\n",
      "=== 📊 Topic Matching Summary ===\n",
      "🔗 Model Topic 1 ↔ Ground Truth T1 — Jaccard: 1.00\n",
      "🔗 Model Topic 3 ↔ Ground Truth T2 — Jaccard: 1.00\n",
      "🔗 Model Topic 2 ↔ Ground Truth T3 — Jaccard: 1.00\n",
      "🔗 Model Topic 4 ↔ Ground Truth T4 — Jaccard: 1.00\n",
      "🔗 Model Topic 0 ↔ Ground Truth T5 — Jaccard: 1.00\n",
      "\n",
      "🧮 Average Jaccard Similarity: 1.0000\n",
      "📈 Ground Truth Coverage: 5/5 (100.0%)\n",
      "\n",
      "=== 🧠 Entity-Level Evaluation ===\n",
      "🎯 Precision: 1.0000\n",
      "🧲 Recall:    1.0000\n",
      "🏅 F1 Score:  1.0000\n",
      "\n",
      "=== Allergy Topic Search ===\n",
      "\n",
      "Enter a query (or type 'exit' to quit): common triggers\n",
      "\n",
      "🔎 Top results for: 'common triggers'\n",
      "🧠 Topic ID: 0\n",
      "🔗 Related Entities: pollen, triggers, allergens, dust mites, pet dander\n",
      "✓ triggers include allergens such as dust mites pet dander and pollen\n",
      "\n",
      "Enter a query (or type 'exit' to quit): symptoms of atopic dermatitis'\n",
      "\n",
      "🔎 Top results for: 'symptoms of atopic dermatitis''\n",
      "🧠 Topic ID: 3\n",
      "🔗 Related Entities: infections, scaly patches, dry\n",
      "✓ patients with atopic dermatitis often have dry scaly patches and may experience infections\n",
      "\n",
      "Enter a query (or type 'exit' to quit): how to control atopic dermatitis\n",
      "\n",
      "🔎 Top results for: 'how to control atopic dermatitis'\n",
      "🧠 Topic ID: 1\n",
      "🔗 Related Entities: skin condition, itchy, inflamed skin, atopic dermatitis\n",
      "✓ atopic dermatitis is a chronic skin condition characterized by itchy and inflamed skin\n",
      "\n",
      "Enter a query (or type 'exit' to quit): Exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS & SETUP ===\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "import logging\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "import scann\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# === CLEANING & CONTEXT EXTRACTION ===\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_entity_contexts(chunks, entities_per_chunk, use_multi_sentence=True):\n",
    "    entity_context_pairs = []\n",
    "    for idx, ents in enumerate(entities_per_chunk):\n",
    "        chunk = clean_text(chunks[idx])\n",
    "        sentences = sent_tokenize(chunk)\n",
    "        for ent in ents:\n",
    "            ent_lower = ent.lower()\n",
    "            matched = False\n",
    "            for i, sent in enumerate(sentences):\n",
    "                if ent_lower in sent.lower():\n",
    "                    context = (\n",
    "                        \" \".join(sentences[max(0, i - 1): i + 2])\n",
    "                        if use_multi_sentence else sent.strip()\n",
    "                    )\n",
    "                    entity_context_pairs.append((ent_lower, context.strip()))\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                entity_context_pairs.append((ent_lower, chunk))\n",
    "    return entity_context_pairs\n",
    "\n",
    "# === TOPIC SEARCHER CLASS ===\n",
    "class AllergyTopicSearcher:\n",
    "    def __init__(self, chunks, entities_per_chunk, umap_params, hdbscan_params, model_name=\"all-mpnet-base-v2\"):\n",
    "        self.chunks = chunks\n",
    "        self.entities_per_chunk = entities_per_chunk\n",
    "        self.embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "        self.umap_params = umap_params\n",
    "        self.hdbscan_params = hdbscan_params\n",
    "\n",
    "        self.topic_model = None\n",
    "        self.topic_metadata = []\n",
    "        self.topic_embeddings = None\n",
    "        self.searcher = None\n",
    "\n",
    "        self._prepare()\n",
    "\n",
    "    def _prepare(self):\n",
    "        entity_context_pairs = extract_entity_contexts(\n",
    "            self.chunks,\n",
    "            self.entities_per_chunk,\n",
    "            use_multi_sentence=True\n",
    "        )\n",
    "\n",
    "        if not entity_context_pairs:\n",
    "            raise ValueError(\"No entity-context pairs extracted!\")\n",
    "\n",
    "        contextual_texts = [f\"{ent}: {context}\" for ent, context in entity_context_pairs]\n",
    "        contextual_embeddings = self.embedding_model.encode(contextual_texts, normalize_embeddings=True)\n",
    "\n",
    "        umap_model = UMAP(**self.umap_params)\n",
    "        hdbscan_model = HDBSCAN(**self.hdbscan_params, prediction_data=True)\n",
    "\n",
    "        self.topic_model = BERTopic(\n",
    "            embedding_model=self.embedding_model,\n",
    "            umap_model=umap_model,\n",
    "            hdbscan_model=hdbscan_model,\n",
    "            representation_model=KeyBERTInspired(),\n",
    "            calculate_probabilities=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        topics, _ = self.topic_model.fit_transform(contextual_texts, embeddings=contextual_embeddings)\n",
    "\n",
    "        topic_to_contexts = defaultdict(list)\n",
    "        topic_to_entities = defaultdict(set)\n",
    "        topic_to_embeddings = defaultdict(list)\n",
    "\n",
    "        for i, topic in enumerate(topics):\n",
    "            ent, context = entity_context_pairs[i]\n",
    "            topic_to_contexts[topic].append(context)\n",
    "            topic_to_entities[topic].add(ent)\n",
    "            topic_to_embeddings[topic].append(contextual_embeddings[i])\n",
    "\n",
    "        topic_embeddings = []\n",
    "        topic_metadata = []\n",
    "\n",
    "        for topic_id in topic_to_contexts:\n",
    "            embeddings = topic_to_embeddings[topic_id]\n",
    "            mean_emb = np.mean(embeddings, axis=0)\n",
    "            mean_emb /= np.linalg.norm(mean_emb) + 1e-10\n",
    "            topic_embeddings.append(mean_emb)\n",
    "            topic_metadata.append({\n",
    "                \"topic_id\": topic_id,\n",
    "                \"entities\": list(topic_to_entities[topic_id]),\n",
    "                \"sentences\": topic_to_contexts[topic_id],\n",
    "                \"sentence_embeddings\": np.array(embeddings)\n",
    "            })\n",
    "\n",
    "        self.topic_embeddings = np.array(topic_embeddings)\n",
    "        self.topic_metadata = topic_metadata\n",
    "\n",
    "        print(\"\\n=== Topics and Associated Entities ===\")\n",
    "        for meta in self.topic_metadata:\n",
    "            print(f\"Topic ID: {meta['topic_id']}, Entities: {', '.join(meta['entities'])}\")\n",
    "\n",
    "        if len(self.topic_embeddings) < 1:\n",
    "            raise RuntimeError(\"No topic embeddings to index.\")\n",
    "\n",
    "        num_clusters = min(len(self.topic_embeddings), 3)\n",
    "        self.searcher = (\n",
    "            scann.scann_ops_pybind.builder(self.topic_embeddings, 3, \"dot_product\")\n",
    "            .tree(num_leaves=num_clusters, num_leaves_to_search=2, training_sample_size=len(self.topic_embeddings))\n",
    "            .score_brute_force()\n",
    "            .reorder(3)\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "    def search(self, query, top_k_topics=1, top_k_sents=1):\n",
    "        query_emb = self.embedding_model.encode([query], normalize_embeddings=True)[0]\n",
    "        neighbors, scores = self.searcher.search(query_emb, final_num_neighbors=top_k_topics)\n",
    "\n",
    "        results = []\n",
    "        for idx in neighbors:\n",
    "            meta = self.topic_metadata[idx]\n",
    "            seen = set()\n",
    "            unique_sentences = []\n",
    "            unique_embeddings = []\n",
    "\n",
    "            for sent, emb in zip(meta[\"sentences\"], meta[\"sentence_embeddings\"]):\n",
    "                if sent not in seen:\n",
    "                    seen.add(sent)\n",
    "                    unique_sentences.append(sent)\n",
    "                    unique_embeddings.append(emb)\n",
    "\n",
    "            sent_embs = np.array(unique_embeddings)\n",
    "            sent_embs_norm = sent_embs / np.linalg.norm(sent_embs, axis=1, keepdims=True)\n",
    "            sims = np.dot(sent_embs_norm, query_emb)\n",
    "            top_indices = sims.argsort()[::-1][:top_k_sents]\n",
    "            top_sents = [(unique_sentences[i], sims[i]) for i in top_indices]\n",
    "\n",
    "            results.append({\n",
    "                \"topic_id\": meta[\"topic_id\"],\n",
    "                \"entities\": meta[\"entities\"],\n",
    "                \"sentences\": top_sents,\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "# === EVALUATION METRICS ===\n",
    "def compute_bertopic_coherence(topic_model, topic_metadata, topk=15):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    topic_word_lists = [[word for word, _ in topic] for topic in topics]\n",
    "\n",
    "    texts = []\n",
    "    for meta in topic_metadata:\n",
    "        for sent in meta[\"sentences\"]:\n",
    "            tokens = clean_text(sent).split()\n",
    "            texts.append(tokens)\n",
    "\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_word_lists,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence=\"c_v\"\n",
    "    )\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "def compute_topic_diversity(topic_model, topic_metadata, topk=10):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    all_words = [word for topic in topics for word, _ in topic]\n",
    "    return len(set(all_words)) / (len(topics) * topk)\n",
    "\n",
    "def compute_silhouette_score_custom(topic_metadata):\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for meta in topic_metadata:\n",
    "        embeddings = meta[\"sentence_embeddings\"]\n",
    "        labels = [meta[\"topic_id\"]] * len(embeddings)\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0:\n",
    "        return None\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    n_samples = all_embeddings.shape[0]\n",
    "    n_labels = len(set(all_labels))\n",
    "\n",
    "    if n_labels < 2 or n_labels > n_samples - 1:\n",
    "        return None\n",
    "\n",
    "    return silhouette_score(all_embeddings, all_labels, metric=\"cosine\")\n",
    "\n",
    "# === DATASET & INITIALIZATION ===\n",
    "allergy_dataset = {\n",
    "   \"chunks\": [\n",
    "            \"Atopic dermatitis is a chronic skin condition characterized by itchy and inflamed skin.\",\n",
    "            \"Patients with atopic dermatitis often have dry, scaly patches and may experience infections.\",\n",
    "            \"Treatment includes moisturizers, corticosteroids, and avoiding irritants.\",\n",
    "            \"Severe cases may require systemic immunosuppressants.\",\n",
    "            \"Triggers include allergens such as dust mites, pet dander, and pollen.\"\n",
    "        ],\n",
    "  \"entities\": [\n",
    "            [\"atopic dermatitis\", \"skin condition\", \"itchy\", \"inflamed skin\"],\n",
    "            [\"dry\", \"scaly patches\", \"infections\"],\n",
    "            [\"treatment\", \"moisturizers\", \"corticosteroids\", \"irritants\"],\n",
    "            [\"severe cases\", \"systemic immunosuppressants\"],\n",
    "            [\"triggers\", \"allergens\", \"dust mites\", \"pet dander\", \"pollen\"]\n",
    "        ]\n",
    "}\n",
    "\n",
    "best_umap = {\"n_neighbors\": 5, \"n_components\": 5, \"min_dist\": 0.1, \"metric\": \"cosine\"}\n",
    "best_hdbscan = {\"min_cluster_size\": 2, \"min_samples\": 1, \"metric\": \"euclidean\"}\n",
    "\n",
    "print(\"Preparing Allergy Topic Searcher...\")\n",
    "searcher = AllergyTopicSearcher(\n",
    "    chunks=allergy_dataset[\"chunks\"],\n",
    "    entities_per_chunk=allergy_dataset[\"entities\"],\n",
    "    umap_params=best_umap,\n",
    "    hdbscan_params=best_hdbscan,\n",
    "    model_name=\"all-mpnet-base-v2\"\n",
    ")\n",
    "print(\"✅ Model ready for querying.\")\n",
    "\n",
    "# === METRICS ===\n",
    "coherence = compute_bertopic_coherence(searcher.topic_model, searcher.topic_metadata, topk=15)\n",
    "diversity = compute_topic_diversity(searcher.topic_model, searcher.topic_metadata, topk=10)\n",
    "sil_score = compute_silhouette_score_custom(searcher.topic_metadata)\n",
    "\n",
    "print(\"\\n=== Topic Quality Metrics ===\")\n",
    "print(f\"🧪 Coherence Score (c_v): {coherence:.4f}\")\n",
    "print(f\"🌈 Topic Diversity: {diversity:.4f}\")\n",
    "if sil_score is not None:\n",
    "    print(f\"📐 Silhouette Score: {sil_score:.4f}\")\n",
    "else:\n",
    "    print(\"📐 Silhouette Score: Not applicable.\")\n",
    "\n",
    "# === GROUND TRUTH TOPICS ===\n",
    "ground_truth_topics = [\n",
    "    {\"topic_id\": \"T1\", \"entities\": [\"atopic dermatitis\", \"skin condition\", \"itchy\", \"inflamed skin\"]},\n",
    "    {\"topic_id\": \"T2\", \"entities\": [\"dry\", \"scaly patches\", \"infections\"]},\n",
    "    {\"topic_id\": \"T3\", \"entities\": [\"treatment\", \"moisturizers\", \"corticosteroids\", \"irritants\"]},\n",
    "    {\"topic_id\": \"T4\", \"entities\": [\"severe cases\", \"systemic immunosuppressants\"]},\n",
    "    {\"topic_id\": \"T5\", \"entities\": [\"triggers\", \"allergens\", \"dust mites\", \"pet dander\", \"pollen\"]}\n",
    "]\n",
    "\n",
    "# === EVALUATION CODE ===\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def normalize(entities):\n",
    "    return [e.lower().strip() for e in entities]\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    set1, set2 = set(set1), set(set2)\n",
    "    return len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0.0\n",
    "\n",
    "# Prepare model topics\n",
    "model_topics = [\n",
    "    {\"topic_id\": meta[\"topic_id\"], \"entities\": normalize(meta[\"entities\"])}\n",
    "    for meta in searcher.topic_metadata\n",
    "]\n",
    "\n",
    "# Matching model topics to ground truth\n",
    "matched_gt_ids = set()\n",
    "matches = []\n",
    "all_model_entities = []\n",
    "all_gt_entities = []\n",
    "\n",
    "for mt in model_topics:\n",
    "    best_score = 0\n",
    "    best_gt = None\n",
    "    for gt in ground_truth_topics:\n",
    "        score = jaccard_similarity(mt[\"entities\"], normalize(gt[\"entities\"]))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_gt = gt\n",
    "    if best_gt:\n",
    "        matches.append((mt[\"topic_id\"], best_gt[\"topic_id\"], best_score))\n",
    "        matched_gt_ids.add(best_gt[\"topic_id\"])\n",
    "\n",
    "        # Collect entities for entity-level precision/recall\n",
    "        all_model_entities.extend(mt[\"entities\"])\n",
    "        all_gt_entities.extend(normalize(best_gt[\"entities\"]))\n",
    "\n",
    "# Entity-level metrics\n",
    "model_entity_counter = Counter(all_model_entities)\n",
    "gt_entity_counter = Counter(all_gt_entities)\n",
    "\n",
    "unique_entities = list(set(list(model_entity_counter.keys()) + list(gt_entity_counter.keys())))\n",
    "y_true = [gt_entity_counter[e] > 0 for e in unique_entities]\n",
    "y_pred = [model_entity_counter[e] > 0 for e in unique_entities]\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "# Print evaluation\n",
    "print(\"\\n=== 📊 Topic Matching Summary ===\")\n",
    "for model_id, gt_id, score in matches:\n",
    "    print(f\"🔗 Model Topic {model_id} ↔ Ground Truth {gt_id} — Jaccard: {score:.2f}\")\n",
    "\n",
    "print(f\"\\n🧮 Average Jaccard Similarity: {sum(score for _, _, score in matches) / len(matches):.4f}\")\n",
    "print(f\"📈 Ground Truth Coverage: {len(matched_gt_ids)}/{len(ground_truth_topics)} \"\n",
    "      f\"({(len(matched_gt_ids)/len(ground_truth_topics))*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== 🧠 Entity-Level Evaluation ===\")\n",
    "print(f\"🎯 Precision: {precision:.4f}\")\n",
    "print(f\"🧲 Recall:    {recall:.4f}\")\n",
    "print(f\"🏅 F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# === QUERY LOOP ===\n",
    "print(\"\\n=== Allergy Topic Search ===\")\n",
    "while True:\n",
    "    query = input(\"\\nEnter a query (or type 'exit' to quit): \").strip()\n",
    "    if query.lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    results = searcher.search(query, top_k_topics=1, top_k_sents=3)\n",
    "    print(f\"\\n🔎 Top results for: '{query}'\")\n",
    "    for res in results:\n",
    "        print(f\"🧠 Topic ID: {res['topic_id']}\")\n",
    "        print(f\"🔗 Related Entities: {', '.join(res['entities'])}\")\n",
    "        for sent, _ in res[\"sentences\"]:\n",
    "            print(f\"✓ {sent}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XehPSvBQ76tR"
   },
   "outputs": [],
   "source": [
    "#Experiemnt on dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m44EPoOsg8Oj",
    "outputId": "5bea8b1f-8210-4ff4-f741-2625f6eb24c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Allergy Topic Searcher...\n",
      "\n",
      "=== Topics and Associated Entities ===\n",
      "Topic ID: 1, Entities: reactions, food allergies, anaphylaxis, hives\n",
      "Topic ID: 0, Entities: peanuts, common food allergens, eggs, wheat, shellfish, milk, tree nuts, fish, soy\n",
      "Topic ID: 3, Entities: treatment, anaphylaxis, epinephrine\n",
      "Topic ID: 2, Entities: swelling, difficulty breathing, symptoms, rash\n",
      "Topic ID: 4, Entities: avoidance, management\n",
      "✅ Model ready for querying.\n",
      "\n",
      "=== Topic Quality Metrics ===\n",
      "🧪 Coherence Score (c_v): 0.9326\n",
      "🌈 Topic Diversity: 0.5200\n",
      "📐 Silhouette Score: 0.8557\n",
      "\n",
      "=== 📊 Topic Matching Summary ===\n",
      "🔗 Model Topic 1 ↔ Ground Truth T1 — Jaccard: 1.00\n",
      "🔗 Model Topic 0 ↔ Ground Truth T2 — Jaccard: 1.00\n",
      "🔗 Model Topic 3 ↔ Ground Truth T3 — Jaccard: 1.00\n",
      "🔗 Model Topic 2 ↔ Ground Truth T4 — Jaccard: 1.00\n",
      "🔗 Model Topic 4 ↔ Ground Truth T5 — Jaccard: 1.00\n",
      "\n",
      "🧮 Average Jaccard Similarity: 1.0000\n",
      "📈 Ground Truth Coverage: 5/5 (100.0%)\n",
      "\n",
      "=== 🧠 Entity-Level Evaluation ===\n",
      "🎯 Precision: 1.0000\n",
      "🧲 Recall:    1.0000\n",
      "🏅 F1 Score:  1.0000\n",
      "\n",
      "=== Allergy Topic Search ===\n",
      "\n",
      "Enter a query (or type 'exit' to quit): which are the foods that cause allergy\n",
      "\n",
      "🔎 Top results for: 'which are the foods that cause allergy'\n",
      "🧠 Topic ID: 0\n",
      "🔗 Related Entities: peanuts, common food allergens, eggs, wheat, shellfish, milk, tree nuts, fish, soy\n",
      "✓ common food allergens include peanuts tree nuts milk eggs wheat soy fish and shellfish\n",
      "\n",
      "Enter a query (or type 'exit' to quit): effects of food allergy\n",
      "\n",
      "🔎 Top results for: 'effects of food allergy'\n",
      "🧠 Topic ID: 1\n",
      "🔗 Related Entities: reactions, food allergies, anaphylaxis, hives\n",
      "✓ food allergies can cause a range of reactions from mild hives to severe anaphylaxis\n",
      "\n",
      "Enter a query (or type 'exit' to quit): how to reduce the allergy caused by foof\n",
      "\n",
      "🔎 Top results for: 'how to reduce the allergy caused by foof'\n",
      "🧠 Topic ID: 4\n",
      "🔗 Related Entities: avoidance, management\n",
      "✓ avoidance of allergens is key to management\n",
      "\n",
      "Enter a query (or type 'exit' to quit): exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS & SETUP ===\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "import logging\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "import scann\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# === CLEANING & CONTEXT EXTRACTION ===\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_entity_contexts(chunks, entities_per_chunk, use_multi_sentence=True):\n",
    "    entity_context_pairs = []\n",
    "    for idx, ents in enumerate(entities_per_chunk):\n",
    "        chunk = clean_text(chunks[idx])\n",
    "        sentences = sent_tokenize(chunk)\n",
    "        for ent in ents:\n",
    "            ent_lower = ent.lower()\n",
    "            matched = False\n",
    "            for i, sent in enumerate(sentences):\n",
    "                if ent_lower in sent.lower():\n",
    "                    context = (\n",
    "                        \" \".join(sentences[max(0, i - 1): i + 2])\n",
    "                        if use_multi_sentence else sent.strip()\n",
    "                    )\n",
    "                    entity_context_pairs.append((ent_lower, context.strip()))\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                entity_context_pairs.append((ent_lower, chunk))\n",
    "    return entity_context_pairs\n",
    "\n",
    "# === TOPIC SEARCHER CLASS ===\n",
    "class AllergyTopicSearcher:\n",
    "    def __init__(self, chunks, entities_per_chunk, umap_params, hdbscan_params, model_name=\"all-mpnet-base-v2\"):\n",
    "        self.chunks = chunks\n",
    "        self.entities_per_chunk = entities_per_chunk\n",
    "        self.embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "        self.umap_params = umap_params\n",
    "        self.hdbscan_params = hdbscan_params\n",
    "\n",
    "        self.topic_model = None\n",
    "        self.topic_metadata = []\n",
    "        self.topic_embeddings = None\n",
    "        self.searcher = None\n",
    "\n",
    "        self._prepare()\n",
    "\n",
    "    def _prepare(self):\n",
    "        entity_context_pairs = extract_entity_contexts(\n",
    "            self.chunks,\n",
    "            self.entities_per_chunk,\n",
    "            use_multi_sentence=True\n",
    "        )\n",
    "\n",
    "        if not entity_context_pairs:\n",
    "            raise ValueError(\"No entity-context pairs extracted!\")\n",
    "\n",
    "        contextual_texts = [f\"{ent}: {context}\" for ent, context in entity_context_pairs]\n",
    "        contextual_embeddings = self.embedding_model.encode(contextual_texts, normalize_embeddings=True)\n",
    "\n",
    "        umap_model = UMAP(**self.umap_params)\n",
    "        hdbscan_model = HDBSCAN(**self.hdbscan_params, prediction_data=True)\n",
    "\n",
    "        self.topic_model = BERTopic(\n",
    "            embedding_model=self.embedding_model,\n",
    "            umap_model=umap_model,\n",
    "            hdbscan_model=hdbscan_model,\n",
    "            representation_model=KeyBERTInspired(),\n",
    "            calculate_probabilities=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        topics, _ = self.topic_model.fit_transform(contextual_texts, embeddings=contextual_embeddings)\n",
    "\n",
    "        topic_to_contexts = defaultdict(list)\n",
    "        topic_to_entities = defaultdict(set)\n",
    "        topic_to_embeddings = defaultdict(list)\n",
    "\n",
    "        for i, topic in enumerate(topics):\n",
    "            ent, context = entity_context_pairs[i]\n",
    "            topic_to_contexts[topic].append(context)\n",
    "            topic_to_entities[topic].add(ent)\n",
    "            topic_to_embeddings[topic].append(contextual_embeddings[i])\n",
    "\n",
    "        topic_embeddings = []\n",
    "        topic_metadata = []\n",
    "\n",
    "        for topic_id in topic_to_contexts:\n",
    "            embeddings = topic_to_embeddings[topic_id]\n",
    "            mean_emb = np.mean(embeddings, axis=0)\n",
    "            mean_emb /= np.linalg.norm(mean_emb) + 1e-10\n",
    "            topic_embeddings.append(mean_emb)\n",
    "            topic_metadata.append({\n",
    "                \"topic_id\": topic_id,\n",
    "                \"entities\": list(topic_to_entities[topic_id]),\n",
    "                \"sentences\": topic_to_contexts[topic_id],\n",
    "                \"sentence_embeddings\": np.array(embeddings)\n",
    "            })\n",
    "\n",
    "        self.topic_embeddings = np.array(topic_embeddings)\n",
    "        self.topic_metadata = topic_metadata\n",
    "\n",
    "        print(\"\\n=== Topics and Associated Entities ===\")\n",
    "        for meta in self.topic_metadata:\n",
    "            print(f\"Topic ID: {meta['topic_id']}, Entities: {', '.join(meta['entities'])}\")\n",
    "\n",
    "        if len(self.topic_embeddings) < 1:\n",
    "            raise RuntimeError(\"No topic embeddings to index.\")\n",
    "\n",
    "        num_clusters = min(len(self.topic_embeddings), 3)\n",
    "        self.searcher = (\n",
    "            scann.scann_ops_pybind.builder(self.topic_embeddings, 3, \"dot_product\")\n",
    "            .tree(num_leaves=num_clusters, num_leaves_to_search=2, training_sample_size=len(self.topic_embeddings))\n",
    "            .score_brute_force()\n",
    "            .reorder(3)\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "    def search(self, query, top_k_topics=1, top_k_sents=1):\n",
    "        query_emb = self.embedding_model.encode([query], normalize_embeddings=True)[0]\n",
    "        neighbors, scores = self.searcher.search(query_emb, final_num_neighbors=top_k_topics)\n",
    "\n",
    "        results = []\n",
    "        for idx in neighbors:\n",
    "            meta = self.topic_metadata[idx]\n",
    "            seen = set()\n",
    "            unique_sentences = []\n",
    "            unique_embeddings = []\n",
    "\n",
    "            for sent, emb in zip(meta[\"sentences\"], meta[\"sentence_embeddings\"]):\n",
    "                if sent not in seen:\n",
    "                    seen.add(sent)\n",
    "                    unique_sentences.append(sent)\n",
    "                    unique_embeddings.append(emb)\n",
    "\n",
    "            sent_embs = np.array(unique_embeddings)\n",
    "            sent_embs_norm = sent_embs / np.linalg.norm(sent_embs, axis=1, keepdims=True)\n",
    "            sims = np.dot(sent_embs_norm, query_emb)\n",
    "            top_indices = sims.argsort()[::-1][:top_k_sents]\n",
    "            top_sents = [(unique_sentences[i], sims[i]) for i in top_indices]\n",
    "\n",
    "            results.append({\n",
    "                \"topic_id\": meta[\"topic_id\"],\n",
    "                \"entities\": meta[\"entities\"],\n",
    "                \"sentences\": top_sents,\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "# === EVALUATION METRICS ===\n",
    "def compute_bertopic_coherence(topic_model, topic_metadata, topk=15):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    topic_word_lists = [[word for word, _ in topic] for topic in topics]\n",
    "\n",
    "    texts = []\n",
    "    for meta in topic_metadata:\n",
    "        for sent in meta[\"sentences\"]:\n",
    "            tokens = clean_text(sent).split()\n",
    "            texts.append(tokens)\n",
    "\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_word_lists,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence=\"c_v\"\n",
    "    )\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "def compute_topic_diversity(topic_model, topic_metadata, topk=10):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    all_words = [word for topic in topics for word, _ in topic]\n",
    "    return len(set(all_words)) / (len(topics) * topk)\n",
    "\n",
    "def compute_silhouette_score_custom(topic_metadata):\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for meta in topic_metadata:\n",
    "        embeddings = meta[\"sentence_embeddings\"]\n",
    "        labels = [meta[\"topic_id\"]] * len(embeddings)\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0:\n",
    "        return None\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    n_samples = all_embeddings.shape[0]\n",
    "    n_labels = len(set(all_labels))\n",
    "\n",
    "    if n_labels < 2 or n_labels > n_samples - 1:\n",
    "        return None\n",
    "\n",
    "    return silhouette_score(all_embeddings, all_labels, metric=\"cosine\")\n",
    "\n",
    "# === DATASET & INITIALIZATION ===\n",
    "allergy_dataset = {\n",
    "   \"chunks\": [\n",
    "            \"Food allergies can cause a range of reactions from mild hives to severe anaphylaxis.\",\n",
    "            \"Common food allergens include peanuts, tree nuts, milk, eggs, wheat, soy, fish, and shellfish.\",\n",
    "            \"Anaphylaxis requires immediate treatment with epinephrine.\",\n",
    "            \"Symptoms can include swelling, difficulty breathing, and rash.\",\n",
    "            \"Avoidance of allergens is key to management.\"\n",
    "        ],\n",
    "    \"entities\": [\n",
    "            [\"food allergies\", \"reactions\", \"hives\", \"anaphylaxis\"],\n",
    "            [\"common food allergens\", \"peanuts\", \"tree nuts\", \"milk\", \"eggs\", \"wheat\", \"soy\", \"fish\", \"shellfish\"],\n",
    "            [\"anaphylaxis\", \"treatment\", \"epinephrine\"],\n",
    "            [\"symptoms\", \"swelling\", \"difficulty breathing\", \"rash\"],\n",
    "            [\"avoidance\", \"management\"]\n",
    "\n",
    "        ]\n",
    "}\n",
    "\n",
    "best_umap = {\"n_neighbors\": 5, \"n_components\": 5, \"min_dist\": 0.1, \"metric\": \"cosine\"}\n",
    "best_hdbscan = {\"min_cluster_size\": 2, \"min_samples\": 1, \"metric\": \"euclidean\"}\n",
    "\n",
    "print(\"Preparing Allergy Topic Searcher...\")\n",
    "searcher = AllergyTopicSearcher(\n",
    "    chunks=allergy_dataset[\"chunks\"],\n",
    "    entities_per_chunk=allergy_dataset[\"entities\"],\n",
    "    umap_params=best_umap,\n",
    "    hdbscan_params=best_hdbscan,\n",
    "    model_name=\"all-mpnet-base-v2\"\n",
    ")\n",
    "print(\"✅ Model ready for querying.\")\n",
    "\n",
    "# === METRICS ===\n",
    "coherence = compute_bertopic_coherence(searcher.topic_model, searcher.topic_metadata, topk=15)\n",
    "diversity = compute_topic_diversity(searcher.topic_model, searcher.topic_metadata, topk=10)\n",
    "sil_score = compute_silhouette_score_custom(searcher.topic_metadata)\n",
    "\n",
    "print(\"\\n=== Topic Quality Metrics ===\")\n",
    "print(f\"🧪 Coherence Score (c_v): {coherence:.4f}\")\n",
    "print(f\"🌈 Topic Diversity: {diversity:.4f}\")\n",
    "if sil_score is not None:\n",
    "    print(f\"📐 Silhouette Score: {sil_score:.4f}\")\n",
    "else:\n",
    "    print(\"📐 Silhouette Score: Not applicable.\")\n",
    "\n",
    "# === GROUND TRUTH TOPICS ===\n",
    "ground_truth_topics = [\n",
    "    {\"topic_id\": \"T1\", \"entities\": [\"food allergies\", \"reactions\", \"hives\", \"anaphylaxis\"]},\n",
    "    {\"topic_id\": \"T2\", \"entities\": [\"common food allergens\", \"peanuts\", \"tree nuts\", \"milk\", \"eggs\", \"wheat\", \"soy\", \"fish\", \"shellfish\"]},\n",
    "    {\"topic_id\": \"T3\", \"entities\": [\"anaphylaxis\", \"treatment\", \"epinephrine\"]},\n",
    "    {\"topic_id\": \"T4\", \"entities\": [\"symptoms\", \"swelling\", \"difficulty breathing\", \"rash\"]},\n",
    "    {\"topic_id\": \"T5\", \"entities\": [\"avoidance\", \"management\"]}\n",
    "]\n",
    "\n",
    "# === EVALUATION CODE ===\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def normalize(entities):\n",
    "    return [e.lower().strip() for e in entities]\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    set1, set2 = set(set1), set(set2)\n",
    "    return len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0.0\n",
    "\n",
    "# Prepare model topics\n",
    "model_topics = [\n",
    "    {\"topic_id\": meta[\"topic_id\"], \"entities\": normalize(meta[\"entities\"])}\n",
    "    for meta in searcher.topic_metadata\n",
    "]\n",
    "\n",
    "# Matching model topics to ground truth\n",
    "matched_gt_ids = set()\n",
    "matches = []\n",
    "all_model_entities = []\n",
    "all_gt_entities = []\n",
    "\n",
    "for mt in model_topics:\n",
    "    best_score = 0\n",
    "    best_gt = None\n",
    "    for gt in ground_truth_topics:\n",
    "        score = jaccard_similarity(mt[\"entities\"], normalize(gt[\"entities\"]))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_gt = gt\n",
    "    if best_gt:\n",
    "        matches.append((mt[\"topic_id\"], best_gt[\"topic_id\"], best_score))\n",
    "        matched_gt_ids.add(best_gt[\"topic_id\"])\n",
    "\n",
    "        # Collect entities for entity-level precision/recall\n",
    "        all_model_entities.extend(mt[\"entities\"])\n",
    "        all_gt_entities.extend(normalize(best_gt[\"entities\"]))\n",
    "\n",
    "# Entity-level metrics\n",
    "model_entity_counter = Counter(all_model_entities)\n",
    "gt_entity_counter = Counter(all_gt_entities)\n",
    "\n",
    "unique_entities = list(set(list(model_entity_counter.keys()) + list(gt_entity_counter.keys())))\n",
    "y_true = [gt_entity_counter[e] > 0 for e in unique_entities]\n",
    "y_pred = [model_entity_counter[e] > 0 for e in unique_entities]\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "# Print evaluation\n",
    "print(\"\\n=== 📊 Topic Matching Summary ===\")\n",
    "for model_id, gt_id, score in matches:\n",
    "    print(f\"🔗 Model Topic {model_id} ↔ Ground Truth {gt_id} — Jaccard: {score:.2f}\")\n",
    "\n",
    "print(f\"\\n🧮 Average Jaccard Similarity: {sum(score for _, _, score in matches) / len(matches):.4f}\")\n",
    "print(f\"📈 Ground Truth Coverage: {len(matched_gt_ids)}/{len(ground_truth_topics)} \"\n",
    "      f\"({(len(matched_gt_ids)/len(ground_truth_topics))*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== 🧠 Entity-Level Evaluation ===\")\n",
    "print(f\"🎯 Precision: {precision:.4f}\")\n",
    "print(f\"🧲 Recall:    {recall:.4f}\")\n",
    "print(f\"🏅 F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# === QUERY LOOP ===\n",
    "print(\"\\n=== Allergy Topic Search ===\")\n",
    "while True:\n",
    "    query = input(\"\\nEnter a query (or type 'exit' to quit): \").strip()\n",
    "    if query.lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    results = searcher.search(query, top_k_topics=1, top_k_sents=3)\n",
    "    print(f\"\\n🔎 Top results for: '{query}'\")\n",
    "    for res in results:\n",
    "        print(f\"🧠 Topic ID: {res['topic_id']}\")\n",
    "        print(f\"🔗 Related Entities: {', '.join(res['entities'])}\")\n",
    "        for sent, _ in res[\"sentences\"]:\n",
    "            print(f\"✓ {sent}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lEG3FyU795q"
   },
   "outputs": [],
   "source": [
    "#Experiemnt on dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGXU3lhEhEsK",
    "outputId": "86a10f11-be9c-4d49-9300-cab68769b3b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Allergy Topic Searcher...\n",
      "\n",
      "=== Topics and Associated Entities ===\n",
      "Topic ID: 0, Entities: pollen, allergic rhinitis, seasonal allergic rhinitis, dust, pollen season, allergic response, airborne particles, pet dander\n",
      "Topic ID: 1, Entities: runny nose, itchy eyes, sneezing, symptoms, nasal congestion\n",
      "Topic ID: 3, Entities: treatment, nasal corticosteroids, avoiding triggers, antihistamines\n",
      "Topic ID: 2, Entities: pollen, common triggers, dust mites, mold, pet dander\n",
      "✅ Model ready for querying.\n",
      "\n",
      "=== Topic Quality Metrics ===\n",
      "🧪 Coherence Score (c_v): 0.8624\n",
      "🌈 Topic Diversity: 0.7250\n",
      "📐 Silhouette Score: 0.6324\n",
      "\n",
      "=== 📊 Topic Matching Summary ===\n",
      "🔗 Model Topic 0 ↔ Ground Truth T1 — Jaccard: 0.75\n",
      "🔗 Model Topic 1 ↔ Ground Truth T2 — Jaccard: 1.00\n",
      "🔗 Model Topic 3 ↔ Ground Truth T3 — Jaccard: 1.00\n",
      "🔗 Model Topic 2 ↔ Ground Truth T4 — Jaccard: 1.00\n",
      "\n",
      "🧮 Average Jaccard Similarity: 0.9375\n",
      "📈 Ground Truth Coverage: 4/5 (80.0%)\n",
      "\n",
      "=== 🧠 Entity-Level Evaluation ===\n",
      "🎯 Precision: 0.9000\n",
      "🧲 Recall:    1.0000\n",
      "🏅 F1 Score:  0.9474\n",
      "\n",
      "=== Allergy Topic Search ===\n",
      "\n",
      "Enter a query (or type 'exit' to quit): whi can get the allergic rhinitis\n",
      "\n",
      "🔎 Top results for: 'whi can get the allergic rhinitis'\n",
      "🧠 Topic ID: 0\n",
      "🔗 Related Entities: pollen, allergic rhinitis, seasonal allergic rhinitis, dust, pollen season, allergic response, airborne particles, pet dander\n",
      "✓ allergic rhinitis is caused by an allergic response to airborne particles like pollen dust and pet dander\n",
      "✓ seasonal allergic rhinitis is often worse during pollen season\n",
      "\n",
      "Enter a query (or type 'exit' to quit): how to prevent it\n",
      "\n",
      "🔎 Top results for: 'how to prevent it'\n",
      "🧠 Topic ID: 2\n",
      "🔗 Related Entities: pollen, common triggers, dust mites, mold, pet dander\n",
      "✓ common triggers include pollen dust mites mold and pet dander\n",
      "\n",
      "Enter a query (or type 'exit' to quit): medication taken\n",
      "\n",
      "🔎 Top results for: 'medication taken'\n",
      "🧠 Topic ID: 3\n",
      "🔗 Related Entities: treatment, nasal corticosteroids, avoiding triggers, antihistamines\n",
      "✓ treatment options include antihistamines nasal corticosteroids and avoiding triggers\n",
      "\n",
      "Enter a query (or type 'exit' to quit): symptoms observed\n",
      "\n",
      "🔎 Top results for: 'symptoms observed'\n",
      "🧠 Topic ID: 1\n",
      "🔗 Related Entities: runny nose, itchy eyes, sneezing, symptoms, nasal congestion\n",
      "✓ symptoms include sneezing nasal congestion runny nose and itchy eyes\n",
      "\n",
      "Enter a query (or type 'exit' to quit): exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS & SETUP ===\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "import logging\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "import scann\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# === CLEANING & CONTEXT EXTRACTION ===\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_entity_contexts(chunks, entities_per_chunk, use_multi_sentence=True):\n",
    "    entity_context_pairs = []\n",
    "    for idx, ents in enumerate(entities_per_chunk):\n",
    "        chunk = clean_text(chunks[idx])\n",
    "        sentences = sent_tokenize(chunk)\n",
    "        for ent in ents:\n",
    "            ent_lower = ent.lower()\n",
    "            matched = False\n",
    "            for i, sent in enumerate(sentences):\n",
    "                if ent_lower in sent.lower():\n",
    "                    context = (\n",
    "                        \" \".join(sentences[max(0, i - 1): i + 2])\n",
    "                        if use_multi_sentence else sent.strip()\n",
    "                    )\n",
    "                    entity_context_pairs.append((ent_lower, context.strip()))\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                entity_context_pairs.append((ent_lower, chunk))\n",
    "    return entity_context_pairs\n",
    "\n",
    "# === TOPIC SEARCHER CLASS ===\n",
    "class AllergyTopicSearcher:\n",
    "    def __init__(self, chunks, entities_per_chunk, umap_params, hdbscan_params, model_name=\"all-mpnet-base-v2\"):\n",
    "        self.chunks = chunks\n",
    "        self.entities_per_chunk = entities_per_chunk\n",
    "        self.embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "        self.umap_params = umap_params\n",
    "        self.hdbscan_params = hdbscan_params\n",
    "\n",
    "        self.topic_model = None\n",
    "        self.topic_metadata = []\n",
    "        self.topic_embeddings = None\n",
    "        self.searcher = None\n",
    "\n",
    "        self._prepare()\n",
    "\n",
    "    def _prepare(self):\n",
    "        entity_context_pairs = extract_entity_contexts(\n",
    "            self.chunks,\n",
    "            self.entities_per_chunk,\n",
    "            use_multi_sentence=True\n",
    "        )\n",
    "\n",
    "        if not entity_context_pairs:\n",
    "            raise ValueError(\"No entity-context pairs extracted!\")\n",
    "\n",
    "        contextual_texts = [f\"{ent}: {context}\" for ent, context in entity_context_pairs]\n",
    "        contextual_embeddings = self.embedding_model.encode(contextual_texts, normalize_embeddings=True)\n",
    "\n",
    "        umap_model = UMAP(**self.umap_params)\n",
    "        hdbscan_model = HDBSCAN(**self.hdbscan_params, prediction_data=True)\n",
    "\n",
    "        self.topic_model = BERTopic(\n",
    "            embedding_model=self.embedding_model,\n",
    "            umap_model=umap_model,\n",
    "            hdbscan_model=hdbscan_model,\n",
    "            representation_model=KeyBERTInspired(),\n",
    "            calculate_probabilities=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        topics, _ = self.topic_model.fit_transform(contextual_texts, embeddings=contextual_embeddings)\n",
    "\n",
    "        topic_to_contexts = defaultdict(list)\n",
    "        topic_to_entities = defaultdict(set)\n",
    "        topic_to_embeddings = defaultdict(list)\n",
    "\n",
    "        for i, topic in enumerate(topics):\n",
    "            ent, context = entity_context_pairs[i]\n",
    "            topic_to_contexts[topic].append(context)\n",
    "            topic_to_entities[topic].add(ent)\n",
    "            topic_to_embeddings[topic].append(contextual_embeddings[i])\n",
    "\n",
    "        topic_embeddings = []\n",
    "        topic_metadata = []\n",
    "\n",
    "        for topic_id in topic_to_contexts:\n",
    "            embeddings = topic_to_embeddings[topic_id]\n",
    "            mean_emb = np.mean(embeddings, axis=0)\n",
    "            mean_emb /= np.linalg.norm(mean_emb) + 1e-10\n",
    "            topic_embeddings.append(mean_emb)\n",
    "            topic_metadata.append({\n",
    "                \"topic_id\": topic_id,\n",
    "                \"entities\": list(topic_to_entities[topic_id]),\n",
    "                \"sentences\": topic_to_contexts[topic_id],\n",
    "                \"sentence_embeddings\": np.array(embeddings)\n",
    "            })\n",
    "\n",
    "        self.topic_embeddings = np.array(topic_embeddings)\n",
    "        self.topic_metadata = topic_metadata\n",
    "\n",
    "        print(\"\\n=== Topics and Associated Entities ===\")\n",
    "        for meta in self.topic_metadata:\n",
    "            print(f\"Topic ID: {meta['topic_id']}, Entities: {', '.join(meta['entities'])}\")\n",
    "\n",
    "        if len(self.topic_embeddings) < 1:\n",
    "            raise RuntimeError(\"No topic embeddings to index.\")\n",
    "\n",
    "        num_clusters = min(len(self.topic_embeddings), 3)\n",
    "        self.searcher = (\n",
    "            scann.scann_ops_pybind.builder(self.topic_embeddings, 3, \"dot_product\")\n",
    "            .tree(num_leaves=num_clusters, num_leaves_to_search=2, training_sample_size=len(self.topic_embeddings))\n",
    "            .score_brute_force()\n",
    "            .reorder(3)\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "    def search(self, query, top_k_topics=1, top_k_sents=1):\n",
    "        query_emb = self.embedding_model.encode([query], normalize_embeddings=True)[0]\n",
    "        neighbors, scores = self.searcher.search(query_emb, final_num_neighbors=top_k_topics)\n",
    "\n",
    "        results = []\n",
    "        for idx in neighbors:\n",
    "            meta = self.topic_metadata[idx]\n",
    "            seen = set()\n",
    "            unique_sentences = []\n",
    "            unique_embeddings = []\n",
    "\n",
    "            for sent, emb in zip(meta[\"sentences\"], meta[\"sentence_embeddings\"]):\n",
    "                if sent not in seen:\n",
    "                    seen.add(sent)\n",
    "                    unique_sentences.append(sent)\n",
    "                    unique_embeddings.append(emb)\n",
    "\n",
    "            sent_embs = np.array(unique_embeddings)\n",
    "            sent_embs_norm = sent_embs / np.linalg.norm(sent_embs, axis=1, keepdims=True)\n",
    "            sims = np.dot(sent_embs_norm, query_emb)\n",
    "            top_indices = sims.argsort()[::-1][:top_k_sents]\n",
    "            top_sents = [(unique_sentences[i], sims[i]) for i in top_indices]\n",
    "\n",
    "            results.append({\n",
    "                \"topic_id\": meta[\"topic_id\"],\n",
    "                \"entities\": meta[\"entities\"],\n",
    "                \"sentences\": top_sents,\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "# === EVALUATION METRICS ===\n",
    "def compute_bertopic_coherence(topic_model, topic_metadata, topk=15):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    topic_word_lists = [[word for word, _ in topic] for topic in topics]\n",
    "\n",
    "    texts = []\n",
    "    for meta in topic_metadata:\n",
    "        for sent in meta[\"sentences\"]:\n",
    "            tokens = clean_text(sent).split()\n",
    "            texts.append(tokens)\n",
    "\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_word_lists,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence=\"c_v\"\n",
    "    )\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "def compute_topic_diversity(topic_model, topic_metadata, topk=10):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    all_words = [word for topic in topics for word, _ in topic]\n",
    "    return len(set(all_words)) / (len(topics) * topk)\n",
    "\n",
    "def compute_silhouette_score_custom(topic_metadata):\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for meta in topic_metadata:\n",
    "        embeddings = meta[\"sentence_embeddings\"]\n",
    "        labels = [meta[\"topic_id\"]] * len(embeddings)\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0:\n",
    "        return None\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    n_samples = all_embeddings.shape[0]\n",
    "    n_labels = len(set(all_labels))\n",
    "\n",
    "    if n_labels < 2 or n_labels > n_samples - 1:\n",
    "        return None\n",
    "\n",
    "    return silhouette_score(all_embeddings, all_labels, metric=\"cosine\")\n",
    "\n",
    "# === DATASET & INITIALIZATION ===\n",
    "allergy_dataset = {\n",
    "   \"chunks\": [\n",
    "            \"Allergic rhinitis is caused by an allergic response to airborne particles like pollen, dust, and pet dander.\",\n",
    "            \"Symptoms include sneezing, nasal congestion, runny nose, and itchy eyes.\",\n",
    "            \"Treatment options include antihistamines, nasal corticosteroids, and avoiding triggers.\",\n",
    "            \"Common triggers include pollen, dust mites, mold, and pet dander.\",\n",
    "            \"Seasonal allergic rhinitis is often worse during pollen season.\"\n",
    "        ],\n",
    "        \"entities\": [\n",
    "            [\"allergic rhinitis\", \"allergic response\", \"airborne particles\", \"pollen\", \"dust\", \"pet dander\"],\n",
    "            [\"symptoms\", \"sneezing\", \"nasal congestion\", \"runny nose\", \"itchy eyes\"],\n",
    "            [\"treatment\", \"antihistamines\", \"nasal corticosteroids\", \"avoiding triggers\"],\n",
    "            [\"common triggers\", \"pollen\", \"dust mites\", \"mold\", \"pet dander\"],\n",
    "            [\"seasonal allergic rhinitis\", \"pollen season\"]\n",
    "        ]\n",
    "\n",
    "}\n",
    "\n",
    "best_umap = {\"n_neighbors\": 5, \"n_components\": 5, \"min_dist\": 0.1, \"metric\": \"cosine\"}\n",
    "best_hdbscan = {\"min_cluster_size\": 2, \"min_samples\": 1, \"metric\": \"euclidean\"}\n",
    "\n",
    "print(\"Preparing Allergy Topic Searcher...\")\n",
    "searcher = AllergyTopicSearcher(\n",
    "    chunks=allergy_dataset[\"chunks\"],\n",
    "    entities_per_chunk=allergy_dataset[\"entities\"],\n",
    "    umap_params=best_umap,\n",
    "    hdbscan_params=best_hdbscan,\n",
    "    model_name=\"all-mpnet-base-v2\"\n",
    ")\n",
    "print(\"✅ Model ready for querying.\")\n",
    "\n",
    "# === METRICS ===\n",
    "coherence = compute_bertopic_coherence(searcher.topic_model, searcher.topic_metadata, topk=15)\n",
    "diversity = compute_topic_diversity(searcher.topic_model, searcher.topic_metadata, topk=10)\n",
    "sil_score = compute_silhouette_score_custom(searcher.topic_metadata)\n",
    "\n",
    "print(\"\\n=== Topic Quality Metrics ===\")\n",
    "print(f\"🧪 Coherence Score (c_v): {coherence:.4f}\")\n",
    "print(f\"🌈 Topic Diversity: {diversity:.4f}\")\n",
    "if sil_score is not None:\n",
    "    print(f\"📐 Silhouette Score: {sil_score:.4f}\")\n",
    "else:\n",
    "    print(\"📐 Silhouette Score: Not applicable.\")\n",
    "\n",
    "# === GROUND TRUTH TOPICS ===\n",
    "ground_truth_topics = [\n",
    "    {\"topic_id\": \"T1\", \"entities\": [\"allergic rhinitis\", \"allergic response\", \"airborne particles\", \"pollen\", \"dust\", \"pet dander\"]},\n",
    "    {\"topic_id\": \"T2\", \"entities\": [\"symptoms\", \"sneezing\", \"nasal congestion\", \"runny nose\", \"itchy eyes\"]},\n",
    "    {\"topic_id\": \"T3\", \"entities\": [\"treatment\", \"antihistamines\", \"nasal corticosteroids\", \"avoiding triggers\"]},\n",
    "    {\"topic_id\": \"T4\", \"entities\": [\"common triggers\", \"pollen\", \"dust mites\", \"mold\", \"pet dander\"]},\n",
    "    {\"topic_id\": \"T5\", \"entities\": [\"seasonal allergic rhinitis\", \"pollen season\"]}\n",
    "]\n",
    "\n",
    "# === EVALUATION CODE ===\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def normalize(entities):\n",
    "    return [e.lower().strip() for e in entities]\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    set1, set2 = set(set1), set(set2)\n",
    "    return len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0.0\n",
    "\n",
    "# Prepare model topics\n",
    "model_topics = [\n",
    "    {\"topic_id\": meta[\"topic_id\"], \"entities\": normalize(meta[\"entities\"])}\n",
    "    for meta in searcher.topic_metadata\n",
    "]\n",
    "\n",
    "# Matching model topics to ground truth\n",
    "matched_gt_ids = set()\n",
    "matches = []\n",
    "all_model_entities = []\n",
    "all_gt_entities = []\n",
    "\n",
    "for mt in model_topics:\n",
    "    best_score = 0\n",
    "    best_gt = None\n",
    "    for gt in ground_truth_topics:\n",
    "        score = jaccard_similarity(mt[\"entities\"], normalize(gt[\"entities\"]))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_gt = gt\n",
    "    if best_gt:\n",
    "        matches.append((mt[\"topic_id\"], best_gt[\"topic_id\"], best_score))\n",
    "        matched_gt_ids.add(best_gt[\"topic_id\"])\n",
    "\n",
    "        # Collect entities for entity-level precision/recall\n",
    "        all_model_entities.extend(mt[\"entities\"])\n",
    "        all_gt_entities.extend(normalize(best_gt[\"entities\"]))\n",
    "\n",
    "# Entity-level metrics\n",
    "model_entity_counter = Counter(all_model_entities)\n",
    "gt_entity_counter = Counter(all_gt_entities)\n",
    "\n",
    "unique_entities = list(set(list(model_entity_counter.keys()) + list(gt_entity_counter.keys())))\n",
    "y_true = [gt_entity_counter[e] > 0 for e in unique_entities]\n",
    "y_pred = [model_entity_counter[e] > 0 for e in unique_entities]\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "# Print evaluation\n",
    "print(\"\\n=== 📊 Topic Matching Summary ===\")\n",
    "for model_id, gt_id, score in matches:\n",
    "    print(f\"🔗 Model Topic {model_id} ↔ Ground Truth {gt_id} — Jaccard: {score:.2f}\")\n",
    "\n",
    "print(f\"\\n🧮 Average Jaccard Similarity: {sum(score for _, _, score in matches) / len(matches):.4f}\")\n",
    "print(f\"📈 Ground Truth Coverage: {len(matched_gt_ids)}/{len(ground_truth_topics)} \"\n",
    "      f\"({(len(matched_gt_ids)/len(ground_truth_topics))*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== 🧠 Entity-Level Evaluation ===\")\n",
    "print(f\"🎯 Precision: {precision:.4f}\")\n",
    "print(f\"🧲 Recall:    {recall:.4f}\")\n",
    "print(f\"🏅 F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# === QUERY LOOP ===\n",
    "print(\"\\n=== Allergy Topic Search ===\")\n",
    "while True:\n",
    "    query = input(\"\\nEnter a query (or type 'exit' to quit): \").strip()\n",
    "    if query.lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    results = searcher.search(query, top_k_topics=1, top_k_sents=3)\n",
    "    print(f\"\\n🔎 Top results for: '{query}'\")\n",
    "    for res in results:\n",
    "        print(f\"🧠 Topic ID: {res['topic_id']}\")\n",
    "        print(f\"🔗 Related Entities: {', '.join(res['entities'])}\")\n",
    "        for sent, _ in res[\"sentences\"]:\n",
    "            print(f\"✓ {sent}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42cx7vdu8Afy"
   },
   "outputs": [],
   "source": [
    "#Experiemnt on dataset 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PTc2jgiJnPYU",
    "outputId": "3974716e-7715-4a62-e922-71b1466cd582"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Allergy Topic Searcher...\n",
      "\n",
      "=== Topics and Associated Entities ===\n",
      "Topic ID: 2, Entities: migraines, screen exposure, frequent headaches\n",
      "Topic ID: 3, Entities: migraines, family history, maternal side\n",
      "Topic ID: 4, Entities: neurological imaging, no abnormalities, mri\n",
      "Topic ID: 5, Entities: irregular sleep, caffeine, sleep patterns\n",
      "Topic ID: 0, Entities: reduced caffeine, stress management, sleep hygiene, preventive strategies\n",
      "Topic ID: 6, Entities: limited success, pain relievers, over-the-counter medications\n",
      "Topic ID: 1, Entities: polymorphism, cacna1a, familial hemiplegic migraine, genetic testing\n",
      "✅ Model ready for querying.\n",
      "\n",
      "=== Topic Quality Metrics ===\n",
      "🧪 Coherence Score (c_v): 0.9453\n",
      "🌈 Topic Diversity: 0.7571\n",
      "📐 Silhouette Score: 0.8630\n",
      "\n",
      "=== 📊 Topic Matching Summary ===\n",
      "🔗 Model Topic 2 ↔ Ground Truth T1 — Jaccard: 1.00\n",
      "🔗 Model Topic 3 ↔ Ground Truth T2 — Jaccard: 1.00\n",
      "🔗 Model Topic 4 ↔ Ground Truth T3 — Jaccard: 1.00\n",
      "🔗 Model Topic 5 ↔ Ground Truth T4 — Jaccard: 1.00\n",
      "🔗 Model Topic 0 ↔ Ground Truth T5 — Jaccard: 1.00\n",
      "🔗 Model Topic 6 ↔ Ground Truth T6 — Jaccard: 1.00\n",
      "🔗 Model Topic 1 ↔ Ground Truth T7 — Jaccard: 1.00\n",
      "\n",
      "🧮 Average Jaccard Similarity: 1.0000\n",
      "📈 Ground Truth Coverage: 7/7 (100.0%)\n",
      "\n",
      "=== 🧠 Entity-Level Evaluation ===\n",
      "🎯 Precision: 1.0000\n",
      "🧲 Recall:    1.0000\n",
      "🏅 F1 Score:  1.0000\n",
      "\n",
      "=== Allergy Topic Search ===\n",
      "\n",
      "Enter a query (or type 'exit' to quit): history\n",
      "\n",
      "🔎 Top results for: 'history'\n",
      "🧠 Topic ID: 3\n",
      "🔗 Related Entities: migraines, family history, maternal side\n",
      "✓ a family history of migraines is noted particularly on the maternal side\n",
      "\n",
      "Enter a query (or type 'exit' to quit): what could have caused migraine\n",
      "\n",
      "🔎 Top results for: 'what could have caused migraine'\n",
      "🧠 Topic ID: 3\n",
      "🔗 Related Entities: migraines, family history, maternal side\n",
      "✓ a family history of migraines is noted particularly on the maternal side\n",
      "\n",
      "Enter a query (or type 'exit' to quit): how migraine is identified or diagonised\n",
      "\n",
      "🔎 Top results for: 'how migraine is identified or diagonised'\n",
      "🧠 Topic ID: 3\n",
      "🔗 Related Entities: migraines, family history, maternal side\n",
      "✓ a family history of migraines is noted particularly on the maternal side\n",
      "\n",
      "Enter a query (or type 'exit' to quit): is it due to past inheritance\n",
      "\n",
      "🔎 Top results for: 'is it due to past inheritance'\n",
      "🧠 Topic ID: 3\n",
      "🔗 Related Entities: migraines, family history, maternal side\n",
      "✓ a family history of migraines is noted particularly on the maternal side\n",
      "\n",
      "Enter a query (or type 'exit' to quit): exit\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# === IMPORTS & SETUP ===\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import nltk\n",
    "import logging\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from hdbscan import HDBSCAN\n",
    "from umap import UMAP\n",
    "import scann\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# === CLEANING & CONTEXT EXTRACTION ===\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_entity_contexts(chunks, entities_per_chunk, use_multi_sentence=True):\n",
    "    entity_context_pairs = []\n",
    "    for idx, ents in enumerate(entities_per_chunk):\n",
    "        chunk = clean_text(chunks[idx])\n",
    "        sentences = sent_tokenize(chunk)\n",
    "        for ent in ents:\n",
    "            ent_lower = ent.lower()\n",
    "            matched = False\n",
    "            for i, sent in enumerate(sentences):\n",
    "                if ent_lower in sent.lower():\n",
    "                    context = (\n",
    "                        \" \".join(sentences[max(0, i - 1): i + 2])\n",
    "                        if use_multi_sentence else sent.strip()\n",
    "                    )\n",
    "                    entity_context_pairs.append((ent_lower, context.strip()))\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                entity_context_pairs.append((ent_lower, chunk))\n",
    "    return entity_context_pairs\n",
    "\n",
    "# === TOPIC SEARCHER CLASS ===\n",
    "class AllergyTopicSearcher:\n",
    "    def __init__(self, chunks, entities_per_chunk, umap_params, hdbscan_params, model_name=\"all-mpnet-base-v2\"):\n",
    "        self.chunks = chunks\n",
    "        self.entities_per_chunk = entities_per_chunk\n",
    "        self.embedding_model = SentenceTransformer(model_name)\n",
    "\n",
    "        self.umap_params = umap_params\n",
    "        self.hdbscan_params = hdbscan_params\n",
    "\n",
    "        self.topic_model = None\n",
    "        self.topic_metadata = []\n",
    "        self.topic_embeddings = None\n",
    "        self.searcher = None\n",
    "\n",
    "        self._prepare()\n",
    "\n",
    "    def _prepare(self):\n",
    "        entity_context_pairs = extract_entity_contexts(\n",
    "            self.chunks,\n",
    "            self.entities_per_chunk,\n",
    "            use_multi_sentence=True\n",
    "        )\n",
    "\n",
    "        if not entity_context_pairs:\n",
    "            raise ValueError(\"No entity-context pairs extracted!\")\n",
    "\n",
    "        contextual_texts = [f\"{ent}: {context}\" for ent, context in entity_context_pairs]\n",
    "        contextual_embeddings = self.embedding_model.encode(contextual_texts, normalize_embeddings=True)\n",
    "\n",
    "        umap_model = UMAP(**self.umap_params)\n",
    "        hdbscan_model = HDBSCAN(**self.hdbscan_params, prediction_data=True)\n",
    "\n",
    "        self.topic_model = BERTopic(\n",
    "            embedding_model=self.embedding_model,\n",
    "            umap_model=umap_model,\n",
    "            hdbscan_model=hdbscan_model,\n",
    "            representation_model=KeyBERTInspired(),\n",
    "            calculate_probabilities=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        topics, _ = self.topic_model.fit_transform(contextual_texts, embeddings=contextual_embeddings)\n",
    "\n",
    "        topic_to_contexts = defaultdict(list)\n",
    "        topic_to_entities = defaultdict(set)\n",
    "        topic_to_embeddings = defaultdict(list)\n",
    "\n",
    "        for i, topic in enumerate(topics):\n",
    "            ent, context = entity_context_pairs[i]\n",
    "            topic_to_contexts[topic].append(context)\n",
    "            topic_to_entities[topic].add(ent)\n",
    "            topic_to_embeddings[topic].append(contextual_embeddings[i])\n",
    "\n",
    "        topic_embeddings = []\n",
    "        topic_metadata = []\n",
    "\n",
    "        for topic_id in topic_to_contexts:\n",
    "            embeddings = topic_to_embeddings[topic_id]\n",
    "            mean_emb = np.mean(embeddings, axis=0)\n",
    "            mean_emb /= np.linalg.norm(mean_emb) + 1e-10\n",
    "            topic_embeddings.append(mean_emb)\n",
    "            topic_metadata.append({\n",
    "                \"topic_id\": topic_id,\n",
    "                \"entities\": list(topic_to_entities[topic_id]),\n",
    "                \"sentences\": topic_to_contexts[topic_id],\n",
    "                \"sentence_embeddings\": np.array(embeddings)\n",
    "            })\n",
    "\n",
    "        self.topic_embeddings = np.array(topic_embeddings)\n",
    "        self.topic_metadata = topic_metadata\n",
    "\n",
    "        print(\"\\n=== Topics and Associated Entities ===\")\n",
    "        for meta in self.topic_metadata:\n",
    "            print(f\"Topic ID: {meta['topic_id']}, Entities: {', '.join(meta['entities'])}\")\n",
    "\n",
    "        if len(self.topic_embeddings) < 1:\n",
    "            raise RuntimeError(\"No topic embeddings to index.\")\n",
    "\n",
    "        num_clusters = min(len(self.topic_embeddings), 3)\n",
    "        self.searcher = (\n",
    "            scann.scann_ops_pybind.builder(self.topic_embeddings, 3, \"dot_product\")\n",
    "            .tree(num_leaves=num_clusters, num_leaves_to_search=2, training_sample_size=len(self.topic_embeddings))\n",
    "            .score_brute_force()\n",
    "            .reorder(3)\n",
    "            .build()\n",
    "        )\n",
    "\n",
    "    def search(self, query, top_k_topics=1, top_k_sents=1):\n",
    "        query_emb = self.embedding_model.encode([query], normalize_embeddings=True)[0]\n",
    "        neighbors, scores = self.searcher.search(query_emb, final_num_neighbors=top_k_topics)\n",
    "\n",
    "        results = []\n",
    "        for idx in neighbors:\n",
    "            meta = self.topic_metadata[idx]\n",
    "            seen = set()\n",
    "            unique_sentences = []\n",
    "            unique_embeddings = []\n",
    "\n",
    "            for sent, emb in zip(meta[\"sentences\"], meta[\"sentence_embeddings\"]):\n",
    "                if sent not in seen:\n",
    "                    seen.add(sent)\n",
    "                    unique_sentences.append(sent)\n",
    "                    unique_embeddings.append(emb)\n",
    "\n",
    "            sent_embs = np.array(unique_embeddings)\n",
    "            sent_embs_norm = sent_embs / np.linalg.norm(sent_embs, axis=1, keepdims=True)\n",
    "            sims = np.dot(sent_embs_norm, query_emb)\n",
    "            top_indices = sims.argsort()[::-1][:top_k_sents]\n",
    "            top_sents = [(unique_sentences[i], sims[i]) for i in top_indices]\n",
    "\n",
    "            results.append({\n",
    "                \"topic_id\": meta[\"topic_id\"],\n",
    "                \"entities\": meta[\"entities\"],\n",
    "                \"sentences\": top_sents,\n",
    "            })\n",
    "\n",
    "        return results\n",
    "\n",
    "# === EVALUATION METRICS ===\n",
    "def compute_bertopic_coherence(topic_model, topic_metadata, topk=15):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    topic_word_lists = [[word for word, _ in topic] for topic in topics]\n",
    "\n",
    "    texts = []\n",
    "    for meta in topic_metadata:\n",
    "        for sent in meta[\"sentences\"]:\n",
    "            tokens = clean_text(sent).split()\n",
    "            texts.append(tokens)\n",
    "\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_word_lists,\n",
    "        texts=texts,\n",
    "        dictionary=dictionary,\n",
    "        coherence=\"c_v\"\n",
    "    )\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "def compute_topic_diversity(topic_model, topic_metadata, topk=10):\n",
    "    topics = [topic_model.get_topic(meta[\"topic_id\"])[:topk] for meta in topic_metadata]\n",
    "    all_words = [word for topic in topics for word, _ in topic]\n",
    "    return len(set(all_words)) / (len(topics) * topk)\n",
    "\n",
    "def compute_silhouette_score_custom(topic_metadata):\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    for meta in topic_metadata:\n",
    "        embeddings = meta[\"sentence_embeddings\"]\n",
    "        labels = [meta[\"topic_id\"]] * len(embeddings)\n",
    "        all_embeddings.append(embeddings)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "    if len(all_embeddings) == 0:\n",
    "        return None\n",
    "\n",
    "    all_embeddings = np.vstack(all_embeddings)\n",
    "    n_samples = all_embeddings.shape[0]\n",
    "    n_labels = len(set(all_labels))\n",
    "\n",
    "    if n_labels < 2 or n_labels > n_samples - 1:\n",
    "        return None\n",
    "\n",
    "    return silhouette_score(all_embeddings, all_labels, metric=\"cosine\")\n",
    "\n",
    "# === DATASET & INITIALIZATION ===\n",
    "allergy_dataset = {\n",
    "   \"chunks\": [\n",
    "        \"The patient reports frequent migraines, especially after long periods of screen exposure.\",\n",
    "        \"A family history of migraines is noted, particularly on the maternal side.\",\n",
    "        \"Neurological imaging (MRI) showed no abnormalities.\",\n",
    "        \"The patient consumes high amounts of caffeine and has irregular sleep patterns.\",\n",
    "        \"Preventive strategies include regular sleep hygiene, reduced caffeine, and stress management.\",\n",
    "        \"The patient has tried multiple over-the-counter pain relievers with limited success.\",\n",
    "        \"Genetic testing revealed a polymorphism in the CACNA1A gene, associated with familial hemiplegic migraine.\"\n",
    "    ],\n",
    "    \"entities\": [\n",
    "        [\"migraines\", \"screen exposure\", \"frequent headaches\"],\n",
    "        [\"family history\", \"maternal side\", \"migraines\"],\n",
    "        [\"neurological imaging\", \"MRI\", \"no abnormalities\"],\n",
    "        [\"caffeine\", \"irregular sleep\", \"sleep patterns\"],\n",
    "        [\"preventive strategies\", \"sleep hygiene\", \"stress management\", \"reduced caffeine\"],\n",
    "        [\"pain relievers\", \"limited success\", \"over-the-counter medications\"],\n",
    "        [\"genetic testing\", \"CACNA1A\", \"familial hemiplegic migraine\", \"polymorphism\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "best_umap = {\"n_neighbors\": 5, \"n_components\": 5, \"min_dist\": 0.1, \"metric\": \"cosine\"}\n",
    "best_hdbscan = {\"min_cluster_size\": 2, \"min_samples\": 1, \"metric\": \"euclidean\"}\n",
    "\n",
    "print(\"Preparing Allergy Topic Searcher...\")\n",
    "searcher = AllergyTopicSearcher(\n",
    "    chunks=allergy_dataset[\"chunks\"],\n",
    "    entities_per_chunk=allergy_dataset[\"entities\"],\n",
    "    umap_params=best_umap,\n",
    "    hdbscan_params=best_hdbscan,\n",
    "    model_name=\"all-mpnet-base-v2\"\n",
    ")\n",
    "print(\"✅ Model ready for querying.\")\n",
    "\n",
    "# === METRICS ===\n",
    "coherence = compute_bertopic_coherence(searcher.topic_model, searcher.topic_metadata, topk=15)\n",
    "diversity = compute_topic_diversity(searcher.topic_model, searcher.topic_metadata, topk=10)\n",
    "sil_score = compute_silhouette_score_custom(searcher.topic_metadata)\n",
    "\n",
    "print(\"\\n=== Topic Quality Metrics ===\")\n",
    "print(f\"🧪 Coherence Score (c_v): {coherence:.4f}\")\n",
    "print(f\"🌈 Topic Diversity: {diversity:.4f}\")\n",
    "if sil_score is not None:\n",
    "    print(f\"📐 Silhouette Score: {sil_score:.4f}\")\n",
    "else:\n",
    "    print(\"📐 Silhouette Score: Not applicable.\")\n",
    "\n",
    "# === GROUND TRUTH TOPICS ===\n",
    "ground_truth_topics = [\n",
    "    {\"topic_id\": \"T1\", \"entities\": [\"migraines\", \"screen exposure\", \"frequent headaches\"]},\n",
    "    {\"topic_id\": \"T2\", \"entities\": [\"family history\", \"maternal side\", \"migraines\"]},\n",
    "    {\"topic_id\": \"T3\", \"entities\": [\"neurological imaging\", \"MRI\", \"no abnormalities\"]},\n",
    "    {\"topic_id\": \"T4\", \"entities\": [\"caffeine\", \"irregular sleep\", \"sleep patterns\"]},\n",
    "    {\"topic_id\": \"T5\", \"entities\": [\"preventive strategies\", \"sleep hygiene\", \"stress management\", \"reduced caffeine\"]},\n",
    "    {\"topic_id\": \"T6\", \"entities\": [\"pain relievers\", \"limited success\", \"over-the-counter medications\"]},\n",
    "    {\"topic_id\": \"T7\", \"entities\": [\"genetic testing\", \"CACNA1A\", \"familial hemiplegic migraine\", \"polymorphism\"]}\n",
    "]\n",
    "\n",
    "# === EVALUATION CODE ===\n",
    "from collections import Counter\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def normalize(entities):\n",
    "    return [e.lower().strip() for e in entities]\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    set1, set2 = set(set1), set(set2)\n",
    "    return len(set1 & set2) / len(set1 | set2) if set1 | set2 else 0.0\n",
    "\n",
    "# Prepare model topics\n",
    "model_topics = [\n",
    "    {\"topic_id\": meta[\"topic_id\"], \"entities\": normalize(meta[\"entities\"])}\n",
    "    for meta in searcher.topic_metadata\n",
    "]\n",
    "\n",
    "# Matching model topics to ground truth\n",
    "matched_gt_ids = set()\n",
    "matches = []\n",
    "all_model_entities = []\n",
    "all_gt_entities = []\n",
    "\n",
    "for mt in model_topics:\n",
    "    best_score = 0\n",
    "    best_gt = None\n",
    "    for gt in ground_truth_topics:\n",
    "        score = jaccard_similarity(mt[\"entities\"], normalize(gt[\"entities\"]))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_gt = gt\n",
    "    if best_gt:\n",
    "        matches.append((mt[\"topic_id\"], best_gt[\"topic_id\"], best_score))\n",
    "        matched_gt_ids.add(best_gt[\"topic_id\"])\n",
    "\n",
    "        # Collect entities for entity-level precision/recall\n",
    "        all_model_entities.extend(mt[\"entities\"])\n",
    "        all_gt_entities.extend(normalize(best_gt[\"entities\"]))\n",
    "\n",
    "# Entity-level metrics\n",
    "model_entity_counter = Counter(all_model_entities)\n",
    "gt_entity_counter = Counter(all_gt_entities)\n",
    "\n",
    "unique_entities = list(set(list(model_entity_counter.keys()) + list(gt_entity_counter.keys())))\n",
    "y_true = [gt_entity_counter[e] > 0 for e in unique_entities]\n",
    "y_pred = [model_entity_counter[e] > 0 for e in unique_entities]\n",
    "\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "# Print evaluation\n",
    "print(\"\\n=== 📊 Topic Matching Summary ===\")\n",
    "for model_id, gt_id, score in matches:\n",
    "    print(f\"🔗 Model Topic {model_id} ↔ Ground Truth {gt_id} — Jaccard: {score:.2f}\")\n",
    "\n",
    "print(f\"\\n🧮 Average Jaccard Similarity: {sum(score for _, _, score in matches) / len(matches):.4f}\")\n",
    "print(f\"📈 Ground Truth Coverage: {len(matched_gt_ids)}/{len(ground_truth_topics)} \"\n",
    "      f\"({(len(matched_gt_ids)/len(ground_truth_topics))*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n=== 🧠 Entity-Level Evaluation ===\")\n",
    "print(f\"🎯 Precision: {precision:.4f}\")\n",
    "print(f\"🧲 Recall:    {recall:.4f}\")\n",
    "print(f\"🏅 F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# === QUERY LOOP ===\n",
    "print(\"\\n=== Allergy Topic Search ===\")\n",
    "while True:\n",
    "    query = input(\"\\nEnter a query (or type 'exit' to quit): \").strip()\n",
    "    if query.lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    results = searcher.search(query, top_k_topics=1, top_k_sents=3)\n",
    "    print(f\"\\n🔎 Top results for: '{query}'\")\n",
    "    for res in results:\n",
    "        print(f\"🧠 Topic ID: {res['topic_id']}\")\n",
    "        print(f\"🔗 Related Entities: {', '.join(res['entities'])}\")\n",
    "        for sent, _ in res[\"sentences\"]:\n",
    "            print(f\"✓ {sent}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3JQn2Of8Hgw"
   },
   "source": [
    "# Reference notes for metrics used on topic correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYL6Eq4_zABF"
   },
   "outputs": [],
   "source": [
    "#Topic quality or correctness evalauting  metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY3AxgNewiS3"
   },
   "source": [
    "| Metric     | What It Tells You                | Your Result | Interpretation                   |\n",
    "| ---------- | -------------------------------- | ----------- | -------------------------------- |\n",
    "| Coherence  | Topic semantic quality           | 0.8963      | Very coherent, meaningful topics |\n",
    "| Diversity  | How distinct topics are          | 0.8250      | High diversity, little overlap   |\n",
    "| Silhouette | Cluster separation & compactness | 0.7315      | Well-separated, tight clusters   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENguRXlawrlh"
   },
   "source": [
    "**Coherence Score** (c_v): 0.8963\n",
    "\n",
    "What it measures: How semantically coherent or meaningful the words within each topic are when considered together.\n",
    "\n",
    "How it works: It compares how often top words in a topic appear together in the actual data (using word co-occurrence and semantic similarity).\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "Values range roughly from 0 to 1 (sometimes slightly above 1 in some implementations).\n",
    "\n",
    "Higher values (closer to 1) mean the topic words are more related and make more sense together.\n",
    "\n",
    "A score of 0.8963 is quite high, indicating your topics are well-defined and meaningful.\n",
    "\n",
    "🌈 **Topic Diversity** : 0.8250\n",
    "\n",
    "What it measures: How diverse or distinct the topics are from each other based on their top words.\n",
    "\n",
    "How it works: It's the proportion of unique top words across all topics compared to the total number of top words considered.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "Values range from 0 to 1.\n",
    "\n",
    "Closer to 1 means topics are very different from each other (good diversity).\n",
    "\n",
    "Lower means topics overlap a lot, sharing many words.\n",
    "\n",
    "0.8250 means your topics cover a broad range of concepts with relatively little overlap.\n",
    "\n",
    "📐**Silhouette Score**: 0.7315\n",
    "\n",
    "What it measures: How well-separated the clusters/topics are based on the embeddings of their sentences/documents.\n",
    "\n",
    "How it works: It compares the average distance between points in the same cluster to the distance between points in different clusters.\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "Ranges from -1 to +1.\n",
    "\n",
    "Closer to +1 means clusters are well-separated and compact.\n",
    "\n",
    "Around 0 means clusters are overlapping.\n",
    "\n",
    "Negative means points may be assigned to the wrong cluster.\n",
    "\n",
    "0.7315 is a strong positive value, indicating your topic clusters are clearly separated in embedding space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAGteyLKhy2h"
   },
   "outputs": [],
   "source": [
    "#ground truth evaluation metrics explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkCoDCZchaZ9"
   },
   "source": [
    "1. Average Jaccard Similarity\n",
    "✅ What is it?\n",
    "This tells us how similar each model-generated topic is to a ground truth topic based on the overlap of entities.\n",
    "\n",
    "📐 Formula:\n",
    "For two sets of entities\n",
    "𝐴\n",
    "A and\n",
    "𝐵\n",
    "B:\n",
    "\n",
    "Jaccard\n",
    "(\n",
    "𝐴\n",
    ",\n",
    "𝐵\n",
    ")\n",
    "=\n",
    "∣\n",
    "𝐴\n",
    "∩\n",
    "𝐵\n",
    "∣\n",
    "∣\n",
    "𝐴\n",
    "∪\n",
    "𝐵\n",
    "∣\n",
    "Jaccard(A,B)=\n",
    "∣A∪B∣\n",
    "∣A∩B∣\n",
    "​\n",
    "\n",
    "∣\n",
    "𝐴\n",
    "∩\n",
    "𝐵\n",
    "∣\n",
    "∣A∩B∣: number of shared entities\n",
    "\n",
    "∣\n",
    "𝐴\n",
    "∪\n",
    "𝐵\n",
    "∣\n",
    "∣A∪B∣: total unique entities in both\n",
    "\n",
    "📊 How it’s used:\n",
    "For each model topic, we compute the Jaccard score with every ground truth topic and select the best match. Then we take the average of all best-match scores.\n",
    "\n",
    "📈 Why it matters:\n",
    "It gives a quantitative view of how well each generated topic matches a real one. High Jaccard → good topic separation and entity grouping.\n",
    "\n",
    "📈 2. Coverage of Ground Truth Topics\n",
    "✅ What is it?\n",
    "This measures how many of the ground truth topics were matched by at least one model topic.\n",
    "\n",
    "📐 Formula:\n",
    "Coverage\n",
    "=\n",
    "# ground truth topics matched\n",
    "total ground truth topics\n",
    "×\n",
    "100\n",
    "%\n",
    "Coverage=\n",
    "total ground truth topics\n",
    "# ground truth topics matched\n",
    "​\n",
    " ×100%\n",
    "📊 How it’s used:\n",
    "If the model only clusters around a few topics, this score will be low. A good model should cover most or all ground truth topics.\n",
    "\n",
    "📈 Why it matters:\n",
    "Ensures the model isn’t ignoring certain areas or clustering everything into too few topics.\n",
    "\n",
    "🧠 3. Entity-level Precision, Recall, and F1-score\n",
    "✅ What is it?\n",
    "This treats entity extraction like a classification problem:\n",
    "\n",
    "Does the model include the right entities across topics?\n",
    "\n",
    "📐 Definitions:\n",
    "Precision = % of model entities that are correct\n",
    "\n",
    "Recall = % of ground truth entities that were found\n",
    "\n",
    "F1 Score = harmonic mean of precision and recall\n",
    "\n",
    "Precision\n",
    "=\n",
    "TP\n",
    "TP + FP\n",
    ",\n",
    "Recall\n",
    "=\n",
    "TP\n",
    "TP + FN\n",
    ",\n",
    "F1\n",
    "=\n",
    "2\n",
    "⋅\n",
    "Precision\n",
    "⋅\n",
    "Recall\n",
    "Precision + Recall\n",
    "Precision=\n",
    "TP + FP\n",
    "TP\n",
    "​\n",
    " ,Recall=\n",
    "TP + FN\n",
    "TP\n",
    "​\n",
    " ,F1=\n",
    "Precision + Recall\n",
    "2⋅Precision⋅Recall\n",
    "​\n",
    "\n",
    "Where:\n",
    "\n",
    "TP = entity exists in both model and ground truth\n",
    "\n",
    "FP = entity found by model but not in ground truth\n",
    "\n",
    "FN = ground truth entity missed by the model\n",
    "\n",
    "📊 How it’s used:\n",
    "We build a list of all entities found by the model vs ground truth, and compute scores over this list.\n",
    "\n",
    "📈 Why it matters:\n",
    "Even if topics are not perfectly matched, accurate entities still matter — e.g., for medical use cases like yours.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
