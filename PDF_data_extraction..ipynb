{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBoE0f5brEvL"
   },
   "source": [
    "#pre requistes to check:\n",
    "1.Enable these APIs:\n",
    "\n",
    "• Vertex AI API\n",
    "\n",
    "• Cloud Vision API\n",
    "\n",
    "\n",
    "| Package                   | Install Command                                 |\n",
    "| ------------------------- | ----------------------------------------------- |\n",
    "| `google-cloud-vision`     | `pip install --upgrade google-cloud-vision`     |\n",
    "| `google-cloud-aiplatform` | `pip install --upgrade google-cloud-aiplatform` |\n",
    "| `pdf2image`               | `pip install pdf2image`                         |\n",
    "| `poppler-utils` (Linux)   | `sudo apt-get install poppler-utils`            |\n",
    "| `poppler` (Mac)           | `brew install poppler`                          |\n",
    "| `PIL` (Pillow)            | Comes with `pdf2image`                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cN3Mlc63LwPF"
   },
   "source": [
    "| Use case                | Input to Gemini        | When to use                                                       |\n",
    "| ----------------------- | ---------------------- | ----------------------------------------------------------------- |\n",
    "| Text-based extraction   | OCR text only          | When OCR text is clean, simple layout, or you only have text      |\n",
    "| Layout-aware extraction | OCR text + image bytes | When visual layout/formatting is crucial for structure extraction |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYAbd4M6rK9G"
   },
   "source": [
    "#Method 1: Using Gemini 1.0 pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoldwwaGOs7T"
   },
   "outputs": [],
   "source": [
    "#update the folowing things in the below code:\n",
    "#Replace \"your-gcp-project-id\" and \"us-central1\" with your GCP project and region\n",
    "\n",
    "#Replace \"your-gcs-bucket-name\" and \"path/to/your_file.pdf\" with your GCS bucket and PDF path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57KNjJTBkobp"
   },
   "outputs": [],
   "source": [
    "# Step 1: Install Required Libraries\n",
    "!pip install --upgrade google-cloud-vision google-cloud-aiplatform pdf2image\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y poppler-utils\n",
    "\n",
    "# Step 2: Set GCP Configuration\n",
    "from google.cloud import aiplatform, storage\n",
    "from google.cloud import vision\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "from pdf2image import convert_from_bytes\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "\n",
    "# Replace with your actual GCP project and region\n",
    "GCP_PROJECT = \"your-gcp-project-id\"\n",
    "GCP_REGION = \"us-central1\"\n",
    "aiplatform.init(project=GCP_PROJECT, location=GCP_REGION)\n",
    "\n",
    "# Step 3: Download PDF from GCS and convert to images (in-memory)\n",
    "def pdf_to_images_from_gcs(bucket_name, blob_name, dpi=300):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    # Download PDF bytes into memory (no local file)\n",
    "    pdf_bytes = blob.download_as_bytes()\n",
    "    print(f\"Downloaded PDF bytes from gs://{bucket_name}/{blob_name}\")\n",
    "\n",
    "    # Convert PDF bytes directly to images (no local storage)\n",
    "    images = convert_from_bytes(pdf_bytes, dpi=dpi)\n",
    "    print(f\"Converted PDF to {len(images)} images\")\n",
    "    return images\n",
    "\n",
    "# Step 4: Extract OCR text from each image\n",
    "def extract_ocr_from_image(image: Image.Image):\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    with io.BytesIO() as output:\n",
    "        image.save(output, format='PNG')\n",
    "        image_bytes = output.getvalue()\n",
    "\n",
    "    vision_image = vision.Image(content=image_bytes)\n",
    "    response = client.document_text_detection(image=vision_image)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(f\"Vision API Error: {response.error.message}\")\n",
    "\n",
    "    return response.full_text_annotation\n",
    "\n",
    "# Step 5: Flatten OCR annotation to plain text\n",
    "def flatten_ocr_text(annotation):\n",
    "    lines = []\n",
    "    for page in annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            for para in block.paragraphs:\n",
    "                line = \"\"\n",
    "                for word in para.words:\n",
    "                    word_text = ''.join([symbol.text for symbol in word.symbols])\n",
    "                    line += word_text + \" \"\n",
    "                lines.append(line.strip())\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Step 6: Call Gemini 1.0 Pro text-only model to extract structured data\n",
    "def extract_entities_with_gemini_text_model(ocr_text):\n",
    "    prompt = f\"\"\"\n",
    "You are given OCR-extracted text from a PDF page.\n",
    "\n",
    "Your task:\n",
    "1. Identify all headers, sub-headers, and any dates.\n",
    "2. Extract the content that appears under each.\n",
    "3. Return a structured JSON in this format:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"header\": \"Header text\",\n",
    "    \"sub_headers\": [\n",
    "      {{\n",
    "        \"sub_header\": \"Sub-header text\",\n",
    "        \"date\": \"Date (if any)\",\n",
    "        \"content\": \"Associated content\"\n",
    "      }}\n",
    "    ]\n",
    "  }}\n",
    "]\n",
    "\n",
    "OCR Text:\n",
    "\\\"\\\"\\\"\n",
    "{ocr_text}\n",
    "\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "    model = TextGenerationModel.from_pretrained(\"gemini-1.0-pro\")\n",
    "    response = model.predict(\n",
    "        prompt=prompt,\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=2048\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "# Step 7: Full pipeline that processes PDF from GCS bucket\n",
    "def process_pdf_gcs(bucket_name, blob_name):\n",
    "    images = pdf_to_images_from_gcs(bucket_name, blob_name)\n",
    "    results = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        print(f\" Processing page {i + 1}/{len(images)}...\")\n",
    "\n",
    "        ocr_annotation = extract_ocr_from_image(image)\n",
    "        ocr_text = flatten_ocr_text(ocr_annotation)\n",
    "        gemini_output = extract_entities_with_gemini_text_model(ocr_text)\n",
    "\n",
    "        results.append({\n",
    "            \"page\": i + 1,\n",
    "            \"ocr_text\": ocr_text,\n",
    "            \"structured_output\": gemini_output\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "# Step 8: Run the pipeline with your GCS bucket and file path\n",
    "bucket_name = \"your-bucket-name\"\n",
    "blob_name = \"path/to/your_file.pdf\"\n",
    "\n",
    "results = process_pdf_gcs(bucket_name, blob_name)\n",
    "\n",
    "# Step 9: Display the output neatly\n",
    "for r in results:\n",
    "    print(f\"\\n--- Page {r['page']} ---\")\n",
    "    try:\n",
    "        structured = json.loads(r['structured_output'])\n",
    "        print(json.dumps(structured, indent=2))\n",
    "    except Exception as e:\n",
    "        print(\"Could not parse JSON. Raw output:\")\n",
    "        print(r['structured_output'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrThMJkoqHGk"
   },
   "source": [
    "# Option 2: Using the Mulimodal LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3QtYhn3lMEV"
   },
   "outputs": [],
   "source": [
    "#Other alternative\n",
    "#Use Gemini 1.5 Pro Multimodal (image + OCR layout)\n",
    "# This lets Gemini LLM process:\n",
    "\n",
    "# The original image/PDF page\n",
    "\n",
    "# The Vision OCR result (including bounding boxes)\n",
    "\n",
    "# Instructions to identify headers, sub-headers, dates, and associated content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scv2JNIeOYmE"
   },
   "outputs": [],
   "source": [
    "#update the folowing things in the below code:\n",
    "#Replace \"your-gcp-project-id\" and \"us-central1\" with your GCP project and region\n",
    "\n",
    "#Replace \"your-gcs-bucket-name\" and \"path/to/your_file.pdf\" with your GCS bucket and PDF path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyLCFZNGmd-H"
   },
   "outputs": [],
   "source": [
    "# Step 0: Install dependencies (run once in your environment)\n",
    "!pip install --upgrade google-cloud-storage google-cloud-vision google-cloud-aiplatform pdf2image\n",
    "!sudo apt-get update && sudo apt-get install -y poppler-utils\n",
    "\n",
    "from google.cloud import storage, vision\n",
    "from google.cloud import aiplatform\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "from pdf2image import convert_from_bytes\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "\n",
    "# ----------- GCP PROJECT CONFIG -----------\n",
    "GCP_PROJECT = \"your-gcp-project-id\"   # Replace with your project id\n",
    "GCP_LOCATION = \"us-central1\"           # Your region\n",
    "\n",
    "# Initialize Vertex AI for Gemini model usage\n",
    "aiplatform.init(project=GCP_PROJECT, location=GCP_LOCATION)\n",
    "\n",
    "# Initialize global clients\n",
    "storage_client = storage.Client()\n",
    "vision_client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# ----------- Helper functions -----------\n",
    "\n",
    "def pdf_gcs_to_images(bucket_name: str, blob_name: str, dpi: int = 300):\n",
    "    \"\"\"\n",
    "    Download PDF from GCS as bytes, convert to images in-memory.\n",
    "    \"\"\"\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    pdf_bytes = blob.download_as_bytes()\n",
    "    print(f\"Downloaded PDF from gs://{bucket_name}/{blob_name}\")\n",
    "\n",
    "    images = convert_from_bytes(pdf_bytes, dpi=dpi)\n",
    "    print(f\"Converted PDF to {len(images)} images\")\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def extract_ocr_from_image(image: Image.Image):\n",
    "    \"\"\"\n",
    "    Run Google Vision OCR on PIL Image, return annotation and image bytes.\n",
    "    \"\"\"\n",
    "    with io.BytesIO() as output:\n",
    "        image.save(output, format=\"PNG\")\n",
    "        image_bytes = output.getvalue()\n",
    "\n",
    "    vision_image = vision.Image(content=image_bytes)\n",
    "    response = vision_client.document_text_detection(image=vision_image)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(f\"Vision API Error: {response.error.message}\")\n",
    "\n",
    "    return response.full_text_annotation, image_bytes\n",
    "\n",
    "\n",
    "def flatten_ocr_text(annotation):\n",
    "    \"\"\"\n",
    "    Convert Vision OCR annotation into plain text string.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for page in annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            for para in block.paragraphs:\n",
    "                line = \"\"\n",
    "                for word in para.words:\n",
    "                    word_text = ''.join([symbol.text for symbol in word.symbols])\n",
    "                    line += word_text + \" \"\n",
    "                lines.append(line.strip())\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def extract_entities_with_gemini(image_bytes, ocr_text):\n",
    "    \"\"\"\n",
    "    Send image bytes and OCR text to Gemini Multimodal LLM and get structured JSON response.\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"\n",
    "You are given a scanned page of a PDF and its OCR-extracted text.\n",
    "\n",
    "Your task:\n",
    "1. Identify all headers, sub-headers, and any dates.\n",
    "2. Extract the text content that appears under each section.\n",
    "3. Use layout structure (like spacing, font size, boldness) to group content.\n",
    "4. Return structured JSON like:\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"header\": \"Header text\",\n",
    "    \"sub_headers\": [\n",
    "      {\n",
    "        \"sub_header\": \"Sub-header text\",\n",
    "        \"date\": \"Date (if any)\",\n",
    "        \"content\": \"Associated content text\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "    model = GenerativeModel(\"gemini-1.5-pro-preview-0409\")\n",
    "\n",
    "    response = model.generate_content(\n",
    "        [\n",
    "            prompt,\n",
    "            Part.from_data(data=image_bytes, mime_type=\"image/png\"),\n",
    "            Part.from_text(ocr_text)\n",
    "        ],\n",
    "        generation_config={\"temperature\": 0.2, \"max_output_tokens\": 2048}\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "\n",
    "def process_pdf_from_gcs(bucket_name, blob_name):\n",
    "    \"\"\"\n",
    "    Full pipeline: Load PDF from GCS, convert pages to images, run OCR, call Gemini LLM,\n",
    "    and return structured results.\n",
    "    \"\"\"\n",
    "    images = pdf_gcs_to_images(bucket_name, blob_name)\n",
    "    results = []\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        print(f\"Processing page {i + 1} of {len(images)}\")\n",
    "\n",
    "        ocr_annotation, image_bytes = extract_ocr_from_image(image)\n",
    "        ocr_text = flatten_ocr_text(ocr_annotation)\n",
    "        gemini_output = extract_entities_with_gemini(image_bytes, ocr_text)\n",
    "\n",
    "        results.append({\n",
    "            \"page\": i + 1,\n",
    "            \"ocr_text\": ocr_text,\n",
    "            \"structured_output\": gemini_output\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ----------- Run Example -----------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bucket_name = \"your-gcs-bucket-name\"   # Replace with your bucket name\n",
    "    blob_name = \"path/to/your_file.pdf\"    # Replace with your PDF path in bucket\n",
    "\n",
    "    all_results = process_pdf_from_gcs(bucket_name, blob_name)\n",
    "\n",
    "    for result in all_results:\n",
    "        print(f\"\\n--- 📄 Page {result['page']} ---\")\n",
    "        try:\n",
    "            parsed_json = json.loads(result['structured_output'])\n",
    "            print(json.dumps(parsed_json, indent=2))\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Could not parse JSON output, raw text:\")\n",
    "            print(result['structured_output'])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
