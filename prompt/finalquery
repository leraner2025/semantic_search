import json
import re
from datetime import datetime
from typing import Dict, Any, List
from google.cloud import aiplatform
from vertexai.generative_models import GenerativeModel


QUERY_EXPANSION_PROMPT = """
You are an expert medical AI assistant specializing in clinical query expansion.

TASK: Expand the user's query into a comprehensive, detailed clinical description.

INSTRUCTIONS:
1. Expand ALL medical abbreviations to full terms (e.g., HTN → Hypertension, DM → Diabetes Mellitus, SOB → Shortness of Breath)
2. Clarify vague medical terms with specific clinical language
3. Add relevant medical context based on standard clinical practice
4. Identify implicit clinical concepts that should be explicit
5. DO NOT add assumptions beyond reasonable clinical interpretation
6. DO NOT include action verbs like "analyze", "review", "check" unless in original query
7. DO NOT hallucinate information not implied by the query
8. Maintain the original query's intent and scope

EXAMPLES:
- "Pt with DM" → "Patient with Diabetes Mellitus"
- "Check vitals" → "Vital signs measurement including blood pressure, heart rate, temperature, respiratory rate, oxygen saturation"
- "Family hx of heart disease" → "Cardiovascular disease in family including coronary artery disease, myocardial infarction, heart failure"
- "SOB on exertion" → "Shortness of breath on exertion"

Return ONLY valid JSON (no markdown, no explanation):
{{
  "expanded_query": "comprehensive expanded clinical description",
  "abbreviations_expanded": ["list of abbreviations that were expanded"],
  "concepts_added": ["list of medical concepts that were made explicit"]
}}

User Input: {query}
"""

INTENT_EXTRACTION_PROMPT = """
You are an expert clinical intent extraction engine specialized in medical information retrieval and taxonomic classification.

 FIRST: Verify this is a CLINICAL query. If the query is NOT related to healthcare, medical conditions, symptoms, treatments, or clinical information, return:
{{
  "is_clinical": false,
  "reason": "Query is not clinical in nature",
  "intents": []
}}

Examples of NON-CLINICAL queries to reject:
- Weather, sports, entertainment, general knowledge
- Technical/IT support unrelated to medical systems
- Travel, food, shopping (unless medically relevant)

If the query IS clinical, proceed with intent extraction.

TASK: Extract ALL clinical intents from the expanded query and generate specific, granular queries optimized for CUI (Concept Unique Identifier) extraction.

 CRITICAL: EVERY intent MUST have final_queries. Do NOT return any intent without final_queries array populated.

UNDERSTANDING INTENTS:
An intent represents a distinct clinical information need embedded in the query. Queries often contain multiple intents within a single text.

INTENT STRUCTURE - HIERARCHICAL TAXONOMY:

CRITICAL: Create DEEP, MULTI-LEVEL taxonomies. Do NOT create shallow classifications.

Each intent must have a HIERARCHICAL structure with multiple levels of decomposition:

1. **intent_title**: Clear, specific title of the intent
2. **description**: What this intent represents clinically and why it's needed
3. **nature**: HIGH-LEVEL category representing the primary characteristic (Level 1)
4. **sub_nature**: Array of DETAILED subcategories with DEEP taxonomic hierarchy (Levels 2-4+)

**SUB_NATURE STRUCTURE - MULTI-LEVEL DECOMPOSITION:**

Each sub_nature must drill down through MULTIPLE classification levels:

```
{{
  "category": "Level 2 - Broad Clinical Domain>>Level 3 - Specific Clinical Area>>",
    {{          
      "elements": ["Level 5 - Most specific atomic elements"],
      "entities": ["Medical entity types for ontology mapping"]      
    }}
  "elements": ["Discrete medical concepts at this level"],
  "entities": ["Medical entity types"]
}}
```

**ALTERNATIVE FLATTENED STRUCTURE** (if JSON depth is an issue):
```
{{
  "category": "Level 2 Classification >> Level 3 Classification >> Level 4 Classification",
  "elements": ["Most granular atomic concepts"],
  "entities": ["Medical entity types"]
}}
```

**HIERARCHICAL CLASSIFICATION EXAMPLES:**

These examples show the APPROACH, not a template. Apply the same deep thinking to ANY clinical concept.

**Example 1 - Understanding Hierarchical Breakdown for Genetic Information:**

When classifying hereditary disease information, think through these levels:
```
Level 1 (Nature): Clinical History
Level 2: Hereditary Conditions
Level 3: Body System (e.g., Endocrine/Metabolic, Cardiovascular, Neurological)
Level 4: Specific Disease Category
Level 5: Disease Subtypes/Variants

Separate dimension - Relationships:
Level 2: Family Relationships
Level 3: Degree of Relation (First-degree, Second-degree)
Level 4: Specific Relationship Type (Parents, Siblings, Grandparents)
Level 5: Individual Relations (Father, Mother, etc.)

Separate dimension - Disease Impact:
Level 2: Disease Complications
Level 3: Complication Type (Acute, Chronic, Systemic)
Level 4: Organ System Affected
Level 5: Specific Complications
```

**Example 2 - Understanding Hierarchical Breakdown for Symptom Information:**

When classifying symptom characteristics, consider multiple dimensions:
```
Spatial Dimension:
Level 2: Anatomical Characteristics
Level 3: Location Type (Primary location, Radiation pattern)
Level 4: Body Region
Level 5: Specific Anatomical Sites

Qualitative Dimension:
Level 2: Sensory Characteristics  
Level 3: Quality Category (Pressure-type, Sharp-type, Other)
Level 4: Specific Descriptors

Temporal Dimension:
Level 2: Time-Related Characteristics
Level 3: Aspect (Onset, Duration, Pattern)
Level 4: Classification
Level 5: Specific Values

Intensity Dimension:
Level 2: Severity Assessment
Level 3: Measurement Type (Subjective scale, Functional impact)
Level 4: Scale or Impact Category
Level 5: Specific Levels

Contextual Dimension:
Level 2: Modifying Factors
Level 3: Factor Type (Triggering, Relieving, Associated)
Level 4: Category
Level 5: Specific Factors
```

**Example 3 - Understanding Hierarchical Breakdown for Diagnostic Information:**

When classifying laboratory or diagnostic data:
```
Level 1 (Nature): Diagnostic Investigation
Level 2: Investigation Type (Laboratory, Imaging, etc.)
Level 3: Clinical Domain (Chemistry, Hematology, Microbiology, etc.)
Level 4: Test Category (e.g., Metabolic Markers, Cell Counts)
Level 5: Specific Test Components
```

**THE PATTERN TO LEARN:**

For ANY clinical concept, ask yourself:
1. What is the broadest clinical category? (Nature)
2. What major dimensions exist for this concept? (Multiple sub_nature branches)
3. For EACH dimension, how does it break down from general to specific? (3-5 levels)
4. What are the atomic elements at the lowest level? (Elements array)
5. What other related concepts should be captured? (Additional dimensions)

Then apply this systematic breakdown to create your taxonomy, regardless of whether it's a symptom, test, medication, procedure, or any other clinical entity.

**DEPTH REQUIREMENTS:**

1. **Minimum 3-4 levels of classification** for each clinical concept
2. **Drill down from general to specific**: Broad Domain >> Specialty Area >> Clinical Category >> Specific Concept >> Atomic Elements
3. **Create multiple sub_nature entries** representing different classification dimensions (anatomical, temporal, severity, functional, etc.)
4. **Each level adds clinical specificity** that helps in precise documentation and retrieval

**THINKING PROCESS FOR DEEP CLASSIFICATION:**

For EACH clinical concept in the query, ask:
1. What is the broadest category? (Nature)
2. What clinical domain does it belong to? (Level 2)
3. What specialty area within that domain? (Level 3)
4. What specific clinical category? (Level 4)
5. What are the atomic elements? (Level 5)
6. What other dimensions exist? (temporal, severity, anatomical, functional, etc.)
7. Repeat this for EACH dimension

The goal is to create a **RICH, DETAILED, MULTI-DIMENSIONAL taxonomy** that captures ALL aspects of the clinical information need.
5. **final_queries**: Array of HIGHLY SPECIFIC queries for CUI extraction (MANDATORY - MINIMUM 5 queries per intent)

NATURE TAXONOMY GUIDELINES - UNIVERSAL PRINCIPLES:

**NATURE represents the PRIMARY CHARACTERISTIC of the clinical information need.**

**DETERMINING NATURE - FUNDAMENTAL APPROACH:**

Nature should answer: "What is the CORE essence of this clinical information?"

Ask yourself these questions and let the answers guide you to create an appropriate nature:

**Question 1: WHEN does this information relate to?**
- Past events, history, what has already occurred?
- Current state, present condition, what is happening now?
- Future prediction, what might occur, anticipated outcomes?

**Question 2: WHY is this information needed clinically?**
- To understand background and context?
- To assess current status and severity?
- To guide immediate clinical decision-making?
- To predict outcomes or stratify risk?
- To document treatment or intervention?
- To track changes over time?

**Question 3: HOW central is this to the clinical encounter?**
- Is this the MAIN reason for clinical attention (highest priority)?
- Is this SUPPORTING information (provides context but not primary focus)?
- Is this BASELINE/REFERENCE information (establishes normal state)?

**Question 4: WHERE does this information come from?**
- Directly from patient (subjective report)?
- From objective measurement or testing?
- From previous documentation or records?
- From clinical examination or observation?
- From calculation or risk assessment?

**CREATING THE NATURE CLASSIFICATION:**

Based on your answers above, CREATE a nature that:
1. **Captures the essence** - What is the single most important characteristic?
2. **Is clinically meaningful** - Would clinicians understand this categorization?
3. **Is appropriately broad** - Can encompass the full scope of the intent
4. **Is sufficiently specific** - Distinguishes this from other types of information

**NATURE NAMING CONVENTIONS:**

Use clear, descriptive language that reflects the clinical domain:
- Combine clinical concepts naturally (e.g., "Clinical History", "Diagnostic Evaluation", "Treatment Documentation")
- Use hierarchical naming when needed (e.g., "Centrality / Main Problem", "Complementary Context / Supporting Information")
- Avoid overly technical or ambiguous terms
- Ensure the nature name would make sense to clinicians reviewing the taxonomy

**ADAPTIVE NATURE CREATION:**

**For EVERY clinical concept:**
1. Analyze what makes this information unique and important
2. Consider if an existing nature pattern from previous queries applies
3. If no existing pattern fits well, CREATE A NEW NATURE that accurately represents this concept
4. Don't force information into inappropriate categories - let the content guide the classification

**HANDLING COMPLEX INTENTS:**

When a single query contains multiple distinct clinical information needs with fundamentally different purposes:

**Option A - Separate Intents:**
Create multiple intent entries, each with its own appropriate nature
Example: Query about "severe chest pain and family history"
- Intent 1: Nature reflecting the acute symptom (current assessment)
- Intent 2: Nature reflecting the genetic background (historical context)

**Option B - Unified Intent:**
Keep as single intent if one aspect primarily provides context for the other
Choose the nature that represents the PRIMARY information need

**Decision criteria:** Use clinical judgment - which approach creates clearer, more useful taxonomy?

**KEY PRINCIPLES:**

1. **Nature emerges from content** - Don't use predefined categories; analyze each query fresh
2. **Clinical relevance guides naming** - Use terminology that clinicians would understand
3. **Flexibility over rigidity** - Create new natures as needed rather than forcing fits
4. **Consistency where appropriate** - If you encounter similar concepts, consider using similar nature classifications for clarity
5. **Hierarchy when helpful** - Use hierarchical naming (with ">>" or "/") when it adds clarity to the primary characteristic

**VALIDATION:**

After determining a nature, ask yourself:
- Does this accurately capture the PRIMARY characteristic of this clinical information?
- Would a clinician reading this nature understand what type of information this represents?
- Is this distinct enough from other natures in the output?
- Is this broad enough to encompass all sub-natures under it?

Let the clinical content and context drive your nature determination, not predefined templates.

CRITICAL REQUIREMENTS FOR CUI OPTIMIZATION:
- Final queries MUST be highly specific (e.g., "Type 2 Diabetes in father" NOT "Family history of diabetes")
- Each query should target 2-15 CUIs maximum for precise concept matching
- Break down broad concepts into atomic, searchable queries
- Include specific family members, body locations, severity levels, time contexts
- Generate queries that can be directly searched in medical ontologies (SNOMED, UMLS, ICD)

INTENT CATEGORIES (detect dynamically based on query content):
The system can detect ANY clinical intent. Common examples include but are NOT limited to:
- Primary/Secondary Health Concerns
- Family/Medical/Surgical/Social History
- Laboratory/Imaging/Diagnostic Tests
- Symptoms/Signs Assessment
- Vital Signs/Physical Measurements
- Medications/Treatments/Procedures
- Risk Assessment/Screening
- Functional Status/Quality of Life
- Patient Goals/Preferences
- Allergies/Adverse Reactions
- Immunizations
- ANY OTHER clinical information need

 Do NOT limit yourself to this list. Extract ANY distinct clinical intent present in the query.

FINAL QUERIES GENERATION - UNIVERSAL PRINCIPLES:

 CRITICAL: Final queries are generated ONLY from the DEEPEST/LAST LEVEL of your taxonomic hierarchy.

**PRINCIPLE: Queries come from ATOMIC ELEMENTS, not intermediate categories**

**CORRECT APPROACH:**
1. Build your deep hierarchical taxonomy (3-5+ levels)
2. Identify the ATOMIC ELEMENTS at the deepest level of each sub_nature
3. Generate final queries ONLY from these atomic elements
4. Focus on CLINICALLY RELEVANT combinations, not exhaustive permutations

**QUERY GENERATION FROM DEEP TAXONOMY:**

**Step 1 - Identify Atomic Elements:**
Extract elements ONLY from the LAST LEVEL of each classification branch.

Example:
```
Category: "Symptom >> Pain >> Location >> Chest >> Specific Zones"
Elements: ["Substernal", "Precordial", "Left anterior"]
↓
These are atomic - generate queries from these
```

NOT from intermediate levels:
```
Category: "Symptom >> Pain >> Location >> Chest"
↓
This is intermediate - do NOT generate queries here
```

**Step 2 - Selective Combination Strategy:**

DO NOT generate every possible combination. Instead, generate queries based on:

**A) Clinical Relevance:**
- Which combinations are actually documented in medical practice?
- Which combinations are clinically meaningful for diagnosis/treatment?
- Which combinations would appear in medical records?

**B) Common Clinical Patterns:**
- Standard symptom characterizations (e.g., "Chest pain substernal", "Chest pain radiating left arm")
- Typical disease presentations (e.g., "Type 2 Diabetes in father", not every relative)
- Frequently ordered tests (e.g., "Hemoglobin", "LDL cholesterol")

**C) Diagnostic Value:**
- Which queries help narrow differential diagnosis?
- Which queries have distinct CUI mappings?
- Which queries are searchable in medical records?

**FORMULA: Selective Cross-Product of Atomic Elements**

Instead of: [Every element] × [Every other element] = Too many queries

Use: [Core Clinical Concept] + [Clinically Relevant Element Combinations]

**QUALITY OVER QUANTITY:**

Target: 10-30 final queries per intent (not 50-100+)

**For Simple Intents:** 5-15 queries
Example: "Family history of diabetes" → Generate for immediate family (parents, siblings) and common types (Type 1, Type 2), not every possible relative

**For Moderate Intents:** 15-25 queries
Example: "Chest pain assessment" → Generate for key characteristics (location, radiation, quality, severity), not every possible combination

**For Complex Intents:** 25-40 queries
Example: "Comprehensive symptom with multiple dimensions" → Generate most clinically relevant combinations

**PRIORITIZATION RULES:**

1. **First-Degree Relations > Extended Family**
   - Generate: Father, Mother, Siblings
   - Skip (unless specifically mentioned): Cousins, Aunts, Uncles

2. **Common Presentations > Rare Variants**
   - Generate: Type 2 Diabetes (most common)
   - De-prioritize: MODY, Neonatal Diabetes (unless specifically mentioned)

3. **Standard Assessments > Comprehensive Panels**
   - Generate: Core vital signs (BP, HR, Temp, RR, SpO2)
   - Skip: Every possible position/context unless clinically indicated

4. **Documented Characteristics > Theoretical Possibilities**
   - Generate: Standard pain descriptors (sharp, dull, pressure-like)
   - Skip: Every conceivable pain descriptor

**EXAMPLES OF GOOD QUERY GENERATION:**

**Example 1 - Family History of Diabetes:**

Taxonomy has 5 sub_natures with many elements.

 BAD (Too many - 50+ queries):
- Type 1 Diabetes in father
- Type 1 Diabetes in mother
- Type 1 Diabetes in brother
- Type 1 Diabetes in sister
- Type 1 Diabetes in paternal grandfather
- Type 1 Diabetes in maternal grandfather
- ... (continues for all types × all relatives)

 GOOD (Focused - 12 queries):
- Type 1 Diabetes in father
- Type 1 Diabetes in mother
- Type 2 Diabetes in father
- Type 2 Diabetes in mother
- Type 2 Diabetes in sibling
- Type 2 Diabetes in paternal grandparent
- Type 2 Diabetes in maternal grandparent
- Gestational diabetes in mother
- Diabetic nephropathy in parent
- Diabetic retinopathy in parent
- Cardiovascular disease in diabetic father
- Diabetes complications in family

**Example 2 - Chest Pain Symptom:**

Taxonomy has 23 sub_natures with dozens of elements.

 BAD (Too many - 100+ queries):
Every location × every quality × every severity × every trigger × every association...

 GOOD (Focused - 20-25 queries):
- Chest pain substernal (key location)
- Chest pain left-sided (key location)
- Chest pain radiating left arm (critical radiation)
- Chest pain radiating jaw (critical radiation)
- Chest pain pressure-like (key quality)
- Chest pain sharp (key quality)
- Chest pain severe (key severity)
- Chest pain sudden onset (key temporal)
- Chest pain duration minutes (key temporal)
- Chest pain exertion (key trigger)
- Chest pain rest (key trigger)
- Chest pain with diaphoresis (key association)
- Chest pain with dyspnea (key association)
- Chest pain relieved nitroglycerin (key relief)
- Chest pain unable walk (key impact)
- Chest pain severe substernal (multi-dimensional)
- Chest pain pressure-like radiating left arm (multi-dimensional)
- Chest pain exertion with diaphoresis (multi-dimensional)

**ADAPTIVE QUERY GENERATION:**

For ANY clinical concept:

1. **Build deep taxonomy** (3-5 levels, multiple dimensions)
2. **Identify atomic elements** at the deepest level
3. **Select clinically relevant elements** (not all elements)
4. **Generate focused queries** from selected elements
5. **Add key multi-dimensional combinations** where clinically meaningful

**VALIDATION BEFORE RETURNING:**

- Are queries derived from atomic elements (deepest level)?
- Is the number of queries reasonable (10-40 per intent)?
- Are queries clinically relevant and commonly documented?
- Would these queries actually be searched in medical records?
- Do queries avoid redundancy and unnecessary permutations?

**KEY PRINCIPLE:**
Create a RICH taxonomy with deep hierarchical classification, but generate FOCUSED queries from the atomic elements that have the highest clinical relevance and diagnostic value.

Quality and clinical relevance trump exhaustive enumeration.

**QUERY CONCISENESS - UNIVERSAL RULES:**

Remove ALL unnecessary words. Each query should be the SHORTEST medical phrase that uniquely identifies the concept.

**Words to ALWAYS remove:**
- "history of", "family history of", "personal history of"
- "location", "character", "quality", "severity", "assessment", "measurement", "level" (unless medically standard)
- "associated with", "related to"
- Articles: "the", "a", "an"
- "patient", "user", "subject"
- Unnecessary prepositions: "in relation to", "with respect to"

**Standard formats (learn from these patterns, don't limit to them):**
- Relationships: [Condition] in [person/location]
- Characteristics: [Concept] [attribute]
- Measurements: [Test] or [Test] [context]
- Temporal: [Concept] [timeframe]
- Severity: [Symptom] [descriptor]

**Examples across different domains:**
- "Diabetes Mellitus in father" (NOT "Family history of Diabetes Mellitus in father")
- "Chest pain substernal" (NOT "Chest pain location substernal")
- "LDL cholesterol" (NOT "LDL cholesterol level")
- "Heart rate resting" (NOT "Heart rate at rest")
- "Metformin 1000mg twice daily" (NOT "Metformin dosage of 1000mg taken twice daily")
- "Walking difficulty" (NOT "Difficulty with walking")
- "Pain onset sudden" (NOT "Pain with sudden onset")

**ADAPTIVE QUERY GENERATION:**
For ANY new clinical concept encountered:
1. Identify what makes it searchable/specific
2. Break it down into atomic components
3. Generate queries following the conciseness principles
4. Ensure each query targets 2-15 CUIs

The goal is ALWAYS: Generate the most specific, concise, searchable queries possible for precise CUI extraction, regardless of the clinical domain.

**VALIDATION BEFORE RETURNING:**
- Verify EVERY intent has a populated final_queries array
- Verify queries follow the atomic decomposition principle
- Verify queries are concise (typically 2-5 words each)
- Verify queries are specific enough for CUI extraction (2-15 CUIs per query)
- No minimum or maximum number restrictions - generate as many queries as needed for complete coverage

Return ONLY valid JSON (no markdown, no explanation):
{{
  "is_clinical": true,  // Set to false if query is non-clinical
  "reason": "",  // Only if non-clinical
  "original_query": "{original_query}",
  "expanded_query": "{expanded_query}",
  "total_intents_detected": number,
  "intents": [
    {{
      "intent_title": "string",
      "description": "string (explain the clinical purpose and information need)",
      "nature": "string (primary characteristic/category)",
      "sub_nature": [
        {{
          "category": "string (specific clinical domain)",
          "elements": ["specific medical concept 1", "specific medical concept 2", ...],
          "entities": ["entity_type_1", "entity_type_2", ...]
        }}
      ],
      "final_queries": [
        "highly specific query 1",
        "highly specific query 2",
        "highly specific query 3",
        "highly specific query 4",
        "highly specific query 5",
        "... (minimum 5, typically 10-50 for comprehensive coverage without duplic)"
      ]
    }}
  ]
}}

User Input: {expanded_query}
Timestamp: {timestamp}
"""

QUERY_REFINEMENT_PROMPT = """
You are an expert medical query optimizer for CUI extraction systems.

TASK: Review the extracted intents and final queries. Optimize them for maximum conciseness while maintaining medical accuracy and completeness.

OPTIMIZATION PRINCIPLES:

1. **Conciseness**: Remove all unnecessary words while preserving medical meaning
   - Remove verbose phrases like "history of", "associated with", "location", "character"
   - Use shortest medical form: "Diabetes in father" NOT "Family history of Diabetes in father"
   
2. **Specificity for CUI Extraction**: 
   - Each query should target 2-15 CUIs maximum
   - Break down broad concepts into atomic queries
   - Ensure queries are directly searchable in medical ontologies
   
3. **Completeness**:
   - Ensure all clinical dimensions are covered with queries
   - Verify atomic decomposition is thorough
   - Don't remove queries that add value
   
4. **Remove Redundancy**:
   - Eliminate exact duplicate queries
   - Combine only if they represent the same concept
   
5. **Maintain Medical Accuracy**:
   - Don't over-abbreviate if it creates ambiguity
   - Keep standard medical terminology
   - Preserve clinical nuance

UNIVERSAL OPTIMIZATION APPROACH:
- Apply atomic decomposition principle to all intents
- Apply conciseness rules universally
- Let the clinical content dictate the number of queries needed
- No artificial minimum or maximum limits

Return ONLY valid JSON with refined intents:
{{
  "intents": [...refined intents array with optimized queries...],
  "refinements_made": ["list of optimization changes applied"],
  "total_queries": number,
  "optimization_summary": "brief description of improvements made"
}}

Input Intents: {intents_json}
"""


# Pipeline


class ContextualIntentPipeline:    
    def __init__(self, project: str, location: str = "us-central1", 
                 model: str = MODEL_VERSION, 
                 enable_refinement: bool = False):

        aiplatform.init(project=project, location=location)
        self.model = GenerativeModel(model)
        self.enable_refinement = enable_refinement
        
    def _call_model(self, prompt: str, temperature: float = 0.0, max_tokens: int = 8192) -> str:

        try:
            # Reset session to avoid context carryover
            if hasattr(self.model, "session") and self.model.session is not None:
                self.model.session.reset()
            
            response = self.model.generate_content(
                prompt,
                generation_config={
                    "temperature": temperature,
                    "max_output_tokens": max_tokens,
                    "top_p": 0.8,
                    "top_k": 10
                }
            )
            return response.text.strip()
        except Exception as e:
            print(f"Error calling model: {str(e)}")
            return "{}"
    
    def _safe_json(self, text: str) -> Dict[str, Any]:

        # Remove markdown code blocks if present
        text = re.sub(r'```json\s*', '', text)
        text = re.sub(r'```\s*', '', text)
        text = text.strip()
        
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            match = re.search(r'\{.*\}', text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(0))
                except:
                    pass
            
            match = re.search(r'\[.*\]', text, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(0))
                except:
                    pass
            
            print(f"Failed to parse JSON from response: {text[:200]}")
            return {}
    
    def _validate_json_structure(self, data: Dict, required_keys: List[str]) -> bool:

        return all(key in data for key in required_keys)
    
    # STEP 1: Query Expansion
    
    def expand_query(self, query: str) -> Dict[str, Any]:

        prompt = QUERY_EXPANSION_PROMPT.format(query=query)
        raw_response = self._call_model(prompt)
        data = self._safe_json(raw_response)
        
        if not self._validate_json_structure(data, ["expanded_query"]):
            # Fallback to original query if expansion fails
            return {
                "expanded_query": query,
                "abbreviations_expanded": [],
                "concepts_added": []
            }
        
        return {
            "expanded_query": data.get("expanded_query", query),
            "abbreviations_expanded": data.get("abbreviations_expanded", []),
            "concepts_added": data.get("concepts_added", [])
        }
    
    # STEP 2: Intent Extraction
    
    def extract_intents(self, original_query: str, expanded_query: str) -> Dict[str, Any]:

        prompt = INTENT_EXTRACTION_PROMPT.format(
            original_query=original_query,
            expanded_query=expanded_query,
            timestamp=datetime.utcnow().isoformat()
        )
        
        # Use higher token limit for complex queries
        raw_response = self._call_model(prompt, max_tokens=8192)
        data = self._safe_json(raw_response)
        
        # Check if query was rejected as non-clinical
        if not data.get("is_clinical", True):
            return {
                "intents": [],
                "total_intents_detected": 0,
                "is_clinical": False,
                "rejected_reason": data.get("reason", "Query is not clinical"),
                "original_query": original_query,
                "expanded_query": expanded_query
            }
        
        if not self._validate_json_structure(data, ["intents"]):
            return {
                "intents": [],
                "total_intents_detected": 0,
                "error": "Failed to extract intents"
            }
        
        # Validate that all intents have final_queries
        intents = data.get("intents", [])
        validated_intents = []
        
        for idx, intent in enumerate(intents):
            if "final_queries" not in intent or not intent["final_queries"]:
                print(f"  Warning: Intent {idx + 1} '{intent.get('intent_title', 'Unknown')}' has no final_queries. Skipping.")
                continue
            
            # No minimum requirement - let LLM decide based on complexity
            validated_intents.append(intent)
        
        return {
            "intents": validated_intents,
            "total_intents_detected": data.get("total_intents_detected", len(validated_intents)),
            "is_clinical": True,
            "original_query": data.get("original_query", original_query),
            "expanded_query": data.get("expanded_query", expanded_query)
        }
    
    
    # STEP 3: Query Refinement
    
    def refine_queries(self, intents: List[Dict]) -> Dict[str, Any]:

        if not self.enable_refinement or not intents:
            return {
                "intents": intents,
                "refinements_made": [],
                "total_queries": sum(len(intent.get('final_queries', [])) for intent in intents)
            }
        
        prompt = QUERY_REFINEMENT_PROMPT.format(intents_json=json.dumps(intents, indent=2))
        raw_response = self._call_model(prompt, max_tokens=8192)
        data = self._safe_json(raw_response)
        
        if not self._validate_json_structure(data, ["intents"]):
            # Return original if refinement fails
            return {
                "intents": intents,
                "refinements_made": ["Refinement failed - using original"],
                "total_queries": sum(len(intent.get('final_queries', [])) for intent in intents)
            }
        
        return {
            "intents": data.get("intents", intents),
            "refinements_made": data.get("refinements_made", []),
            "total_queries": data.get("total_queries", 0)
        }
    
    # Pipeline exec
    
    def run(self, query: str, verbose: bool = False) -> Dict[str, Any]:

        start_time = datetime.utcnow()
        
        if verbose:
            print(f"Original Query: {query}")
        
        # Step 1: Query Expansion
        expansion_result = self.expand_query(query)
        expanded_query = expansion_result["expanded_query"]
        
        if verbose:
            print(f"Expanded Query: {expanded_query}")
        
        # Step 2: Intent Extraction
        intent_result = self.extract_intents(query, expanded_query)
        
        # Check if query was rejected as non-clinical
        if not intent_result.get("is_clinical", True):
            processing_time = (datetime.utcnow() - start_time).total_seconds()
            
            if verbose:
                print(f"Status: NON-CLINICAL (rejected)")
                print(f"Processing Time: {processing_time:.2f}s\n")
            
            return {
                "original_query": query,
                "expanded_query": expanded_query,
                "intents": [],
                "is_clinical": False,
                "rejected_reason": intent_result.get("rejected_reason", "Query is not clinical"),
                "timestamp": datetime.utcnow().isoformat(),
                "processing_time_seconds": processing_time
            }
        
        intents = intent_result.get("intents", [])
        
        # Step 3: Query Refinement
        if self.enable_refinement and intents:
            refinement_result = self.refine_queries(intents)
            intents = refinement_result["intents"]
        
        # Calculate statistics
        total_queries = sum(len(intent.get('final_queries', [])) for intent in intents)
        total_sub_natures = sum(len(intent.get('sub_nature', [])) for intent in intents)
        processing_time = (datetime.utcnow() - start_time).total_seconds()
        
        if verbose:
            print(f"Status: CLINICAL")
            print(f"Intents: {len(intents)} | Sub-natures: {total_sub_natures} | Queries: {total_queries}")
            print(f"Processing Time: {processing_time:.2f}s\n")
        
        return {
            "original_query": query,
            "expanded_query": expanded_query,
            "abbreviations_expanded": expansion_result.get("abbreviations_expanded", []),
            "concepts_added": expansion_result.get("concepts_added", []),
            "intents": intents,
            "is_clinical": True
            }
        

if __name__ == "__main__":
    PROJECT_ID = PROJECT_ID    
    pipeline = ContextualIntentPipeline(
        project=PROJECT_ID,
        location="us-central1",
        model=MODEL_VERSION,
        enable_refinement=False
    )
    
# Test queries
    test_queries = [
        "Identify the patient’s primary complaint",
        "Find all lab results and indicate which ones are abnormal.",
        "Identify any changes in medication during the hospitalization.",
        "Find all references to imaging studies and their impressions",
        "Based on the clinical note, describe the likely cause of the patient’s shortness of breath and outline the evidence supporting that conclusion.",
        "Describe the complete medication management plan, including new prescriptions, dose adjustments, and discontinued drugs, along with the reasons given and dates."
    ]
    
    for idx, query in enumerate(test_queries, 1):
        print(f"\n{'='*80}")
        print(f"Query {idx}/{len(test_queries)}")
        print(f"{'='*80}")
        
        result = pipeline.run(query, verbose=True)
        
        output_filename = f"query_result_{idx}.json"
        with open(output_filename, 'w') as f:
            json.dump(result, f, indent=2)
        
        print(f"Saved to: {output_filename}")
