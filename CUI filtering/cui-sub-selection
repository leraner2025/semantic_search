import requests
import math
import pandas as pd
from google.cloud import bigquery
import subprocess
import json

headers = None

def gcp_update_header():
    global headers
    tmp = subprocess.run(['gcloud', 'auth', 'print-identity-token'], stdout=subprocess.PIPE, universal_newlines=True)
    if tmp.returncode != 0:
        raise Exception("Cannot get GCP access token")
    identity_token = tmp.stdout.strip()
    headers = {
        "Authorization": f"Bearer {identity_token}",
        "Content-Type": "application/json"
    }

gcp_update_header()

def get_cuis_from_text(text, url):
    payload = {"query_texts": [text], "top_k": 3}  # adjust top_k if needed
    try:
        response = requests.post(url, json=payload, headers=headers)
        response.raise_for_status()
        data = response.json()
        cuis = data.get(text, [])
        print(f"[NER] CUIs retrieved: {len(cuis)}")
        return cuis
    except requests.exceptions.RequestException as e:
        print(f"[NER] Request failed: {e}")
        return []
    except json.JSONDecodeError as e:
        print(f"[NER] JSON decode error: {e}")
        return []

client = bigquery.Client()

# ----------------------------
# Step 1: Load UMLS parent hierarchy
# ----------------------------
class MRRELCache:
    def __init__(self, project_id, dataset, mrrel_table):
        self.project_id = project_id
        self.dataset = dataset
        self.mrrel_table = mrrel_table
        self.parent_map = {}
        self.child_map = {}
        self.loaded = False

    def load(self):
        if self.loaded:
            return
        query = f"""
            SELECT CUI1 AS child_cui, CUI2 AS parent_cui
            FROM `{self.project_id}.{self.dataset}.{self.mrrel_table}`
            WHERE REL = 'PAR'
        """
        df = client.query(query).to_dataframe()
        self.parent_map = df.groupby("child_cui")["parent_cui"].apply(list).to_dict()
        self.child_map = df.groupby("parent_cui")["child_cui"].apply(list).to_dict()
        print(f"[Hierarchy] Loaded {len(self.parent_map)} child CUIs")
        self.loaded = True

# ----------------------------
# Step 2: Compute IC
# ----------------------------
def compute_ic(cuis, descendants_table, project_id, dataset):
    # Fetch # descendants for only relevant CUIs
    if not cuis:
        return {}, 0
    cuis_str = ",".join([f"'{c}'" for c in cuis])
    query = f"""
        SELECT CUI, NarrowerConceptCount AS num_descendants
        FROM `{project_id}.{dataset}.{descendants_table}`
        WHERE CUI IN ({cuis_str})
    """
    df = client.query(query).to_dataframe()
    if df.empty:
        return {}, 0
    total_cuis = df.shape[0]
    df["IC"] = df["num_descendants"].apply(lambda x: -math.log((x + 1)/total_cuis))
    ic_map = dict(zip(df["CUI"], df["IC"]))
    threshold = df["IC"].median()
    print(f"[IC] Computed IC for {len(ic_map)} CUIs. Median threshold: {threshold:.4f}")
    return ic_map, threshold

# ----------------------------
# Step 3: Find all ancestors for a CUI
# ----------------------------
def get_ancestors(cui, parent_map):
    ancestors = set()
    stack = [cui]
    while stack:
        current = stack.pop()
        for parent in parent_map.get(current, []):
            if parent not in ancestors:
                ancestors.add(parent)
                stack.append(parent)
    return ancestors

# ----------------------------
# Step 4: Semantic rollup for text-specific CUIs
# ----------------------------
def semantic_rollup(text, ner_url, mrrel_cache, descendants_table, project_id, dataset):
    # Step 4a: get CUIs from NER
    cuis = get_cuis_from_text(text, ner_url)
    if not cuis:
        print("[Rollup] No CUIs found for text.")
        return pd.DataFrame()

    # Load hierarchy
    mrrel_cache.load()

    # Step 4b: Compute IC for fetched CUIs
    ic_map, threshold = compute_ic(cuis, descendants_table, project_id, dataset)
    if not ic_map:
        print("[Rollup] No IC computed.")
        return pd.DataFrame()

    # Step 4c: Traverse ancestors and collect IC >= threshold
    final_cuis = set()
    for cui in cuis:
        # Include self if IC >= threshold
        if ic_map.get(cui, 0) >= threshold:
            final_cuis.add(cui)
        # check ancestors
        ancestors = get_ancestors(cui, mrrel_cache.parent_map)
        for anc in ancestors:
            if ic_map.get(anc, 0) >= threshold:
                final_cuis.add(anc)

    # Step 4d: Prepare output
    output = [{"CUI": c, "IC": ic_map[c]} for c in final_cuis if c in ic_map]
    df = pd.DataFrame(output)
    df = df.sort_values("IC", ascending=False).reset_index(drop=True)
    print(f"[Rollup] Total filtered CUIs: {len(df)}")
    return df

# ----------------------------
# Example usage
# ----------------------------
if __name__ == "__main__":
    project_id = project_id 
    dataset = dataset
    descendants_table = descendants_table
    mrrel_table = mrrel_table
    url = url

    mrrel_cache = MRRELCache(project_id, dataset, mrrel_table)
    sample_text = "MRI of head"
    result_df = semantic_rollup(sample_text, url, mrrel_cache, descendants_table, project_id, dataset)

    if not result_df.empty:
        print(result_df)
        result_df.to_csv("filtered_cuis.csv", index=False)
        print("[Output] Saved filtered CUIs with IC.")
    else:
        print("[Output] No CUIs passed the threshold.")
