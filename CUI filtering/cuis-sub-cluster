import math
import pandas as pd
import requests
import pickle
import subprocess

# ----------------------------
# Load precomputed hierarchy and IC table
# ----------------------------
with open("mrrel_cache.pkl", "rb") as f:
    mrrel_cache = pickle.load(f)  # contains 'parent_map' and 'child_map'

with open("ic_table.pkl", "rb") as f:
    ic_table = pickle.load(f)  # DataFrame with columns ['CUI', 'num_descendants']

# Convert IC table to dict for fast lookup
ic_dict = dict(zip(ic_table['CUI'], ic_table['num_descendants']))

parent_map = mrrel_cache['parent_map']
child_map = mrrel_cache['child_map']

# ----------------------------
# GCP authentication header
# ----------------------------
headers = None

def gcp_update_header():
    global headers
    tmp = subprocess.run(['gcloud', 'auth', 'print-identity-token'],
                         stdout=subprocess.PIPE, universal_newlines=True)
    if tmp.returncode != 0:
        raise Exception("Cannot get GCP access token")
    identity_token = tmp.stdout.strip()
    headers = {
        "Authorization": f"Bearer {identity_token}",
        "Content-Type": "application/json"
    }

try:
    gcp_update_header()
except Exception as e:
    print(f"[Auth] Warning: Failed to get GCP token â€” {e}")
    headers = {"Content-Type": "application/json"}

# ----------------------------
# Get CUIs from NER API
# ----------------------------
def get_cuis_from_text(text, url):
    payload = {"query_texts": [text], "top_k": 3}  # adjust top_k
    try:
        response = requests.post(url, json=payload, headers=headers)
        response.raise_for_status()
        data = response.json()
        cuis = data.get(text, [])  # adjust based on API
        print(f"[NER] CUIs retrieved: {len(cuis)}")
        return cuis
    except Exception as e:
        print(f"[NER] Error: {e}")
        return []

# ----------------------------
# Ancestor / Descendant traversal
# ----------------------------
def get_ancestors(cui, parent_map):
    ancestors = set()
    stack = [cui]
    while stack:
        current = stack.pop()
        for parent in parent_map.get(current, []):
            if parent not in ancestors:
                ancestors.add(parent)
                stack.append(parent)
    return ancestors

def get_descendants(cui, child_map):
    descendants = set()
    stack = [cui]
    while stack:
        current = stack.pop()
        for child in child_map.get(current, []):
            if child not in descendants:
                descendants.add(child)
                stack.append(child)
    return descendants

# ----------------------------
# Form clusters of related CUIs
# ----------------------------
def form_clusters(cuis):
    clusters = []
    visited = set()

    for cui in cuis:
        if cui in visited:
            continue
        cluster = set()
        stack = [cui]

        while stack:
            current = stack.pop()
            if current not in cluster:
                cluster.add(current)
                visited.add(current)
                # consider only CUIs detected in text
                neighbors = set(get_ancestors(current, parent_map)) & set(cuis)
                neighbors.update(set(get_descendants(current, child_map)) & set(cuis))
                stack.extend(neighbors)

        clusters.append(cluster)
    return clusters

# ----------------------------
# Compute IC
# ----------------------------
def compute_ic(cuis):
    total_cuis = len(cuis)
    ic_map = {}
    for cui in cuis:
        num_descendants = ic_dict.get(cui, 0)
        ic_map[cui] = -math.log((num_descendants + 1) / total_cuis)
    threshold = pd.Series(list(ic_map.values())).quantile(0.75)  # 0.75 quantile
    print(f"[IC] Computed IC for {len(ic_map)} CUIs. Threshold: {threshold:.4f}")
    return ic_map, threshold

# ----------------------------
# Filter CUIs within clusters
# ----------------------------
def filter_clusters_by_ic(clusters, ic_map, threshold):
    filtered_cuis = set()
    for cluster in clusters:
        for cui in cluster:
            if ic_map.get(cui, 0) >= threshold:
                filtered_cuis.add(cui)
    return filtered_cuis

# ----------------------------
# Main pipeline
# ----------------------------
def subselect_cuis(text, ner_url):
    # Step 1: Get CUIs from NER
    cuis = get_cuis_from_text(text, ner_url)
    if not cuis:
        print("[Pipeline] No CUIs detected.")
        return pd.DataFrame()

    # Step 2: Form clusters using all detected CUIs
    clusters = form_clusters(cuis)
    print(f"[Pipeline] Formed {len(clusters)} clusters.")

    # Step 3: Compute IC for all CUIs
    ic_map, threshold = compute_ic(cuis)

    # Step 4: Filter CUIs within clusters by IC threshold
    filtered_cuis = filter_clusters_by_ic(clusters, ic_map, threshold)

    # Step 5: Prepare output DataFrame
    df = pd.DataFrame([{"CUI": cui, "IC": ic_map[cui]} for cui in filtered_cuis])
    df = df.sort_values("IC", ascending=False).reset_index(drop=True)
    print(f"[Pipeline] Selected {len(df)} CUIs after IC filtering.")
    return df

# ----------------------------
# Example usage
# ----------------------------
if __name__ == "__main__":
    sample_text = "MRI of head"
    ner_url = url

    result_df = subselect_cuis(sample_text, ner_url)
    if not result_df.empty:
        print(result_df)
        result_df.to_csv("subselected_cuis.csv", index=False)
        print("[Output] Saved subselected CUIs.")
    else:
        print("[Output] No CUIs passed IC threshold.")
