import requests
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from google.cloud import bigquery, aiplatform
import vertexai
from vertexai.language_models import TextEmbeddingModel
import subprocess
import time
import pandas as pd
from collections import defaultdict

# Initialize Vertex AI
aiplatform.init(project=project_id, location="us-central1")
GEMINI_EMBEDDING_MODEL = "gemini-embedding-001"
gemini_model = TextEmbeddingModel.from_pretrained(GEMINI_EMBEDDING_MODEL)

# GCP Auth Header Setup
headers = None
def gcp_update_header():
    global headers
    tmp = subprocess.run(['gcloud', 'auth', 'print-identity-token'], stdout=subprocess.PIPE, universal_newlines=True)
    if tmp.returncode != 0:
        raise Exception("Cannot get GCP access token")
    identity_token = tmp.stdout.strip()
    headers = {
        "Authorization": f"Bearer {identity_token}",
        "Content-Type": "application/json"
    }
gcp_update_header()

# Step 1: NER API
def call_ner_api(text):
    url = url  # Define your endpoint
    payload = {"query_texts": [text], "top_k": 3}
    try:
        response = requests.post(url, json=payload, headers=headers)
        response.raise_for_status()
        data = response.json()
        return data
    except Exception as e:
        print(f"NER API error: {e}")
        return {}

# Step 2: Extract CUIs
def extract_cuis(ner_response, input_text, max_cuis=10):
    cuis = list(set(ner_response.get(input_text, [])))
    return cuis[:max_cuis]

# Step 3: Retrieve embeddings for CUIs
def get_cui_embeddings(client, project_id, dataset, embedding_table, cuis):
    if not cuis:
        return {}
    cuis_str = ",".join([f"'{c}'" for c in cuis])
    query = f"""
    SELECT REF_CUI, REF_Embedding
    FROM `{project_id}.{dataset}.{embedding_table}`
    WHERE REF_CUI IN UNNEST([{cuis_str}])
    """
    results = client.query(query).result()
    return {row.REF_CUI: row.REF_Embedding for row in results}

# Step 4: Cosine similarity filtering
def filter_by_similarity(note_embedding, cui_embeddings, threshold=0.5):
    if not cui_embeddings:
        return []
    note_vec = np.array(note_embedding).reshape(1, -1)
    cui_ids = list(cui_embeddings.keys())
    cui_matrix = np.array([cui_embeddings[cui] for cui in cui_ids])
    scores = cosine_similarity(note_vec, cui_matrix)[0]
    filtered = [cui for cui, score in zip(cui_ids, scores) if score >= threshold]
    print(f"CUIs above threshold ({threshold}): {len(filtered)}")
    return filtered

# Step 5: Leave-One-Out filtering
def leave_one_out(note_embedding, cui_embeddings, threshold=0.5):
    initial_set = filter_by_similarity(note_embedding, cui_embeddings, threshold)
    if not initial_set:
        return []

    def coverage_score(cui_subset):
        matrix = np.array([cui_embeddings[cui] for cui in cui_subset])
        scores = cosine_similarity(np.array(note_embedding).reshape(1, -1), matrix)[0]
        return np.mean(scores)

    best_set = initial_set.copy()
    improved = True

    while improved and len(best_set) > 1:
        scores = []
        for cui in best_set:
            subset = [c for c in best_set if c != cui]
            score = coverage_score(subset)
            scores.append((cui, score))
        worst_cui, worst_score = min(scores, key=lambda x: x[1])
        current_score = coverage_score(best_set)
        if worst_score >= current_score:
            improved = False
        else:
            best_set.remove(worst_cui)

    print(f"Final CUIs after LOO filtering: {len(best_set)}")
    return best_set

# Step 6: Export
def export_to_csv(cui_list, filename="final_cuis.csv"):
    pd.DataFrame({"CUI": cui_list}).to_csv(filename, index=False)
    print(f"Exported {len(cui_list)} CUIs to {filename}")

# Step 7: Pipeline
def run_pipeline(text, note_embedding, project_id, dataset, embedding_table, export_csv=True):
    client = bigquery.Client()

    ner_response = call_ner_api(text)
    ner_cuis = extract_cuis(ner_response, text)
    cui_embeddings = get_cui_embeddings(client, project_id, dataset, embedding_table, ner_cuis)
    final_cuis = leave_one_out(note_embedding, cui_embeddings, threshold=0.5)

    if export_csv:
        export_to_csv(final_cuis)

    return final_cuis

# Example usage
if __name__ == "__main__":
    text = "mris for 6 months"
    note_embedding = gemini_model.get_embeddings([text])[0].values

    final_cuis = run_pipeline(
        text,
        note_embedding,
        project_id,
        dataset,
        embedding_table,
        export_csv=True
    )

    print(f"\nFinal CUIs selected: {len(final_cuis)}")
    print("Final CUIs:", final_cuis)
