import requests
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from google.cloud import bigquery, aiplatform
import vertexai
from vertexai.language_models import TextEmbeddingModel
import subprocess
import time
import pandas as pd
from collections import defaultdict

# Initialize Vertex AI
aiplatform.init(project=project_id, location="us-central1")
GEMINI_EMBEDDING_MODEL = "gemini-embedding-001"
gemini_model = TextEmbeddingModel.from_pretrained(GEMINI_EMBEDDING_MODEL)

# GCP Auth Header Setup
headers = None
def gcp_update_header():
    global headers
    tmp = subprocess.run(['gcloud', 'auth', 'print-identity-token'], stdout=subprocess.PIPE, universal_newlines=True)
    if tmp.returncode != 0:
        raise Exception("Cannot get GCP access token")
    identity_token = tmp.stdout.strip()
    headers = {
        "Authorization": f"Bearer {identity_token}",
        "Content-Type": "application/json"
    }
gcp_update_header()

# Step 1: NER API
def call_ner_api(text):
    url = url
    payload = {"query_texts": [text], "top_k": 3}
    try:
        response = requests.post(url, json=payload, headers=headers)
        response.raise_for_status()
        data = response.json()         
        cui_count = len(data.get(text, []))
        print(f"API call successful. CUIs returned: {cui_count}")
        return data
    except Exception as e:
        print(f"NER API error: {e}")
        return {}

# Step 2: Extract CUIs
def extract_cuis(ner_response, input_text):
    cuis = list(set(ner_response.get(input_text, [])))
    return cuis

# Step 3: Retrieve embeddings for CUIs
def get_cui_embeddings(client, project_id, dataset, embedding_table, cuis):
    if not cuis:
        return {}
    cuis_str = ",".join([f"'{c}'" for c in cuis])
    query = f"""
    SELECT REF_CUI, REF_Embedding
    FROM `{project_id}.{dataset}.{embedding_table}`
    WHERE REF_CUI IN UNNEST([{cuis_str}])
    """
    results = client.query(query).result()
    return {row.REF_CUI: row.REF_Embedding for row in results}

# Step 4: Cosine similarity filtering
def filter_by_similarity(note_embedding, cui_embeddings, threshold):
    if not cui_embeddings:
        return []
    note_vec = np.array(note_embedding).reshape(1, -1)
    cui_ids = list(cui_embeddings.keys())
    cui_matrix = np.array([cui_embeddings[cui] for cui in cui_ids])
    scores = cosine_similarity(note_vec, cui_matrix)[0]
    filtered = [cui for cui, score in zip(cui_ids, scores) if score >= threshold]
    print(f"CUIs above threshold ({threshold}): {len(filtered)}")
    return filtered

# Step 5: Leave-One-Out filtering with impact display
def leave_one_out(note_embedding, cui_embeddings, threshold=0.5):

    # Step 1: Filter CUIs by similarity threshold
    initial_set = filter_by_similarity(note_embedding, cui_embeddings, threshold)
    if not initial_set:
        return [] 

    # Step 2: Compute full coverage score

    def coverage_score(cui_subset):
        matrix = np.array([cui_embeddings[cui] for cui in cui_subset])
        scores = cosine_similarity(np.array(note_embedding).reshape(1, -1), matrix)[0]
        return np.mean(scores) 

    full_score = coverage_score(initial_set)
    impact_rows = []
    retained_cuis = []

 

    # Step 3: Evaluate each CUI independently

    for cui in initial_set:
        subset = [c for c in initial_set if c != cui]
        score = coverage_score(subset)
        delta = round(full_score - score, 4)
        impact_rows.append({
            'CUI': cui,
            'Coverage Drop': delta
        })

        if delta > 0:
            retained_cuis.append(cui)
            
    # Step 4: Display impact table

    impact_df = pd.DataFrame(impact_rows)
    print("\n Leave-One-Out Impact Table:")
    print(impact_df)

    print(f"\n Final CUIs retained: {len(retained_cuis)}")
    print("Final CUIs:", retained_cuis)

    return retained_cuis


# Step 6: Export
def export_to_csv(cui_list, filename="final_cuisv1.csv"):
    pd.DataFrame({"CUI": cui_list}).to_csv(filename, index=False)
    print(f"Exported {len(cui_list)} CUIs to {filename}")

# Step 7: Pipeline
def run_pipeline(text, note_embedding, project_id, dataset, embedding_table, export_csv=True):
    client = bigquery.Client() 

    # Step 1: NER

    ner_response = call_ner_api(text)
    ner_cuis = extract_cuis(ner_response, text) 

    # Step 2: Get embeddings

    cui_embeddings = get_cui_embeddings(client, project_id, dataset, embedding_table, ner_cuis) 

    # Step 3: Filter by similarity threshold
    
    initial_cuis = filter_by_similarity(note_embedding, cui_embeddings, threshold=0.5) #filter CUIs
    if not initial_cuis:
        print("No CUIs passed the similarity threshold.")
        return [] 

    # Step 4: Coverage BEFORE Leave-One-Out

    initial_embeddings = np.array([cui_embeddings[cui] for cui in initial_cuis])
    initial_centroid = np.mean(initial_embeddings, axis=0).reshape(1, -1)
    initial_score = cosine_similarity(np.array(note_embedding).reshape(1, -1), initial_centroid)[0][0]
    print(f"\nCoverage BEFORE Leave-One-Out: {initial_score:.4f}")
    
    # Step 5: Leave-One-Out filtering
    final_cuis = leave_one_out(note_embedding, cui_embeddings, threshold=0.5)  

    # Step 6: Coverage AFTER Leave-One-Out

    if final_cuis:
        final_embeddings = np.array([cui_embeddings[cui] for cui in final_cuis])
        final_centroid = np.mean(final_embeddings, axis=0).reshape(1, -1)
        final_score = cosine_similarity(np.array(note_embedding).reshape(1, -1), final_centroid)[0][0]
        print(f"Coverage AFTER Leave-One-Out: {final_score:.4f}")
    else:
        print(" No CUIs retained after Leave-One-Out.") 

    # Step 7: Export
    if export_csv:
        export_to_csv(final_cuis)

    return final_cuis

# Example usage
if __name__ == "__main__":
    text = "MRI of head"
    note_embedding = gemini_model.get_embeddings([text])[0].values
    # print(note_embedding)

    final_cuis = run_pipeline(
        text,
        note_embedding,
        project_id,
        dataset,
        embedding_table,
        export_csv=True
    )

    print(f"\nFinal CUIs selected: {len(final_cuis)}")
    print("Final CUIs:", final_cuis)
